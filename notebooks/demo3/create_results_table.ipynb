{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395f44cf",
   "metadata": {},
   "source": [
    "# Demo 3 - Data Ingestion\n",
    "\n",
    "This notebook reads the inference from ceph s3 storage for demo2 and will ingest these inference as a table to trino. These tables will be used for creating visualizations using Apache Superset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4bb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import trino\n",
    "import pandas as pd\n",
    "import glob\n",
    "import config\n",
    "from src.data.s3_communication import S3Communication, S3FileType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2fe317",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Injecting Credentials\n",
    "\n",
    "In order to run this notebook, we need credentials to connect with S3 storage to retrieve data and the Trino server to create tables.\n",
    "\n",
    "In an automated environment, the credentials can be specified in a pipeline's environment variables or through Openshift secrets.\n",
    "\n",
    "For running the notebook in a local environment, we will define them as environment variables in a `credentials.env` file at the root of the project repository, and load them using dotenv. An example of what the contents of `credentials.env` could look like is shown below\n",
    "\n",
    "```\n",
    "# s3 credentials\n",
    "S3_ENDPOINT=https://s3.us-east-1.amazonaws.com\n",
    "S3_BUCKET=ocp-odh-os-demo-s3\n",
    "AWS_ACCESS_KEY_ID=xxx\n",
    "AWS_SECRET_ACCESS_KEY=xxx\n",
    "\n",
    "# trino credentials\n",
    "TRINO_USER=xxx\n",
    "TRINO_PASSWD=xxx\n",
    "TRINO_HOST=trino-secure-odh-trino.apps.odh-cl1.apps.os-climate.org\n",
    "TRINO_PORT=443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84efa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = \"/opt/app-root/src/aicoe-osc-demo\"\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78368e2",
   "metadata": {},
   "source": [
    "## Read Raw Data from S3\n",
    "\n",
    "First, we will read some sample data from s3. We will format the column data types to ensure they can be understood by Trino, as well as rename the columns so that they are compatible with SQL naming conventions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "466e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269aa2fb-e410-49b5-a80e-42fba3874604",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getenv(\"AUTOMATION\"):\n",
    "    if not os.path.exists(config.BASE_INFER_KPI_FOLDER):\n",
    "        pathlib.Path(config.BASE_INFER_KPI_FOLDER).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Download a sample dataset file from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        s3_prefix=config.BASE_INFER_KPI_S3_PREFIX,\n",
    "        destination_dir=config.BASE_INFER_KPI_FOLDER\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f4bdf6-8b20-42a4-9a74-552bfbcec2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>kpi</th>\n",
       "      <th>kpi_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>page</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>source</th>\n",
       "      <th>score</th>\n",
       "      <th>no_ans_score</th>\n",
       "      <th>no_answer_score_plus_boost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>413749035_Eversource Energy_2019-12-31</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>• Our core utility operations performed very w...</td>\n",
       "      <td>Text</td>\n",
       "      <td>13.372849</td>\n",
       "      <td>-10.76948</td>\n",
       "      <td>-25.76948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413749035_Eversource Energy_2019-12-31</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2019</td>\n",
       "      <td>34</td>\n",
       "      <td>The American Council for an Energy-Efficient E...</td>\n",
       "      <td>Text</td>\n",
       "      <td>12.66205</td>\n",
       "      <td>-9.417558</td>\n",
       "      <td>-24.417558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>413749035_Eversource Energy_2019-12-31</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>The Eversource Internal Audit Department perfo...</td>\n",
       "      <td>Text</td>\n",
       "      <td>12.373636</td>\n",
       "      <td>-10.899869</td>\n",
       "      <td>-25.899869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>413749035_Eversource Energy_2019-12-31</td>\n",
       "      <td>In which year was the annual report or the sus...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2019</td>\n",
       "      <td>118</td>\n",
       "      <td>These are referenced throughout our 2019 Susta...</td>\n",
       "      <td>Text</td>\n",
       "      <td>12.245757</td>\n",
       "      <td>-10.556628</td>\n",
       "      <td>-25.556628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>413749035_Eversource Energy_2019-12-31</td>\n",
       "      <td>What is the annual total production from coal?</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>no_answer</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Text</td>\n",
       "      <td>2.720188</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 pdf_name  \\\n",
       "0  413749035_Eversource Energy_2019-12-31   \n",
       "1  413749035_Eversource Energy_2019-12-31   \n",
       "2  413749035_Eversource Energy_2019-12-31   \n",
       "3  413749035_Eversource Energy_2019-12-31   \n",
       "4  413749035_Eversource Energy_2019-12-31   \n",
       "\n",
       "                                                 kpi  kpi_id     answer  page  \\\n",
       "0  In which year was the annual report or the sus...    <NA>       2019     7   \n",
       "1  In which year was the annual report or the sus...    <NA>       2019    34   \n",
       "2  In which year was the annual report or the sus...    <NA>       2019    12   \n",
       "3  In which year was the annual report or the sus...    <NA>       2019   118   \n",
       "4     What is the annual total production from coal?    <NA>  no_answer  <NA>   \n",
       "\n",
       "                                           paragraph source      score  \\\n",
       "0  • Our core utility operations performed very w...   Text  13.372849   \n",
       "1  The American Council for an Energy-Efficient E...   Text   12.66205   \n",
       "2  The Eversource Internal Audit Department perfo...   Text  12.373636   \n",
       "3  These are referenced throughout our 2019 Susta...   Text  12.245757   \n",
       "4                                               <NA>   Text   2.720188   \n",
       "\n",
       "   no_ans_score  no_answer_score_plus_boost  \n",
       "0     -10.76948                   -25.76948  \n",
       "1     -9.417558                  -24.417558  \n",
       "2    -10.899869                  -25.899869  \n",
       "3    -10.556628                  -25.556628  \n",
       "4          <NA>                        <NA>  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_files =  []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0).convert_dtypes().drop(columns=['Unnamed: 0'],axis=1)\n",
    "    list_of_files.append(df)\n",
    "\n",
    "preds_kpi = pd.concat(list_of_files, axis=0, ignore_index=True)\n",
    "\n",
    "len_preds_kpi = len(preds_kpi)\n",
    "\n",
    "# convert columns to specific data types\n",
    "preds_kpi = preds_kpi.convert_dtypes().drop(['index'], axis=1, errors='ignore')\n",
    "preds_kpi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f87ac21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Erik Erlandson <eje@redhat.com>\n",
    "\n",
    "_p2smap = {\"string\": \"varchar\", \"Float64\": \"double\", \"Int64\": \"bigint\"}\n",
    "\n",
    "\n",
    "def pandas_type_to_sql(pt):\n",
    "    st = _p2smap.get(pt)\n",
    "    if st is not None:\n",
    "        return st\n",
    "    raise ValueError(\"unexpected pandas column type '{pt}'\".format(pt=pt))\n",
    "\n",
    "\n",
    "# add ability to specify optional dict for specific fields?\n",
    "# if column name is present, use specified value?\n",
    "def generate_table_schema_pairs(df):\n",
    "    ptypes = [str(e) for e in df.dtypes.to_list()]\n",
    "    stypes = [pandas_type_to_sql(e) for e in ptypes]\n",
    "    pz = list(zip(df.columns.to_list(), stypes))\n",
    "    return \",\\n\".join([\"    {n} {t}\".format(n=e[0], t=e[1]) for e in pz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5230c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 689 entries, 0 to 688\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   pdf_name                    689 non-null    string \n",
      " 1   kpi                         689 non-null    string \n",
      " 2   kpi_id                      0 non-null      Int64  \n",
      " 3   answer                      689 non-null    string \n",
      " 4   page                        555 non-null    Int64  \n",
      " 5   paragraph                   555 non-null    string \n",
      " 6   source                      689 non-null    string \n",
      " 7   score                       689 non-null    Float64\n",
      " 8   no_ans_score                555 non-null    Float64\n",
      " 9   no_answer_score_plus_boost  555 non-null    Float64\n",
      "dtypes: Float64(3), Int64(2), string(5)\n",
      "memory usage: 57.3 KB\n"
     ]
    }
   ],
   "source": [
    "# a way to examine the structure of a pandas data frame\n",
    "preds_kpi.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4078824e",
   "metadata": {},
   "source": [
    "## Save Processed Data to S3\n",
    "\n",
    "Now that our data is in a form ingestible by Trino, we will upload it back into our s3 bucket. This will be the data source for our Trino table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72b3795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# parquet has multiple options for appending or updating data\n",
    "# including adding new files, or appending, sharding directory trees, etc\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0).convert_dtypes().drop(columns=['Unnamed: 0'],axis=1)\n",
    "    ret = s3c.upload_df_to_s3(\n",
    "        df,\n",
    "        s3_prefix=config.BASE_INFER_KPI_TABLE_S3_PREFIX,\n",
    "        s3_key=f\"{os.path.basename(filename).split('.')[0]}.parquet\",\n",
    "        filetype=S3FileType.PARQUET,\n",
    "        index=False,\n",
    "    )\n",
    "    print(ret['ResponseMetadata']['HTTPStatusCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b8af31",
   "metadata": {},
   "source": [
    "## Create a Table on Trino\n",
    "\n",
    "Finally, we will create a table in our Trino database that uses the parquet files we uploaded in the previous section as the data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950868a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use trino password env-var to hold token values\n",
    "JWT_TOKEN = os.environ['TRINO_PASSWD']\n",
    "conn = trino.dbapi.connect(\n",
    "    host=os.environ['TRINO_HOST'],\n",
    "    port=os.environ['TRINO_PORT'],\n",
    "    user=os.environ['TRINO_USER'],\n",
    "    http_scheme='https',\n",
    "    auth=trino.auth.JWTAuthentication(JWT_TOKEN),\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d4860b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sql schema that will correspond to the data types\n",
    "# of columns in the pandas DF\n",
    "# to-do: add some mechanisms for overriding types, either here\n",
    "# or on the pandas data-frame itself before we write it out\n",
    "schema = generate_table_schema_pairs(preds_kpi)\n",
    "\n",
    "tabledef = \"\"\"create table if not exists osc_datacommons_dev.urgentem.infer_kpi(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://{s3_bucket}/{kpi_table_s3_prefix}/'\n",
    ")\"\"\".format(\n",
    "    schema=schema,\n",
    "    s3_bucket=os.environ[\"S3_BUCKET\"],\n",
    "    kpi_table_s3_prefix=config.BASE_INFER_KPI_TABLE_S3_PREFIX,\n",
    ")\n",
    "# tables created externally may not show up immediately in cloud-beaver\n",
    "cur.execute(tabledef)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee568250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sustainability-report-2019',\n",
       " 'In which year was the annual report or the sustainability report published?',\n",
       " None,\n",
       " '2019',\n",
       " 26,\n",
       " 'Equinor Sustainability report 2019 High value — creating shared value',\n",
       " 'Text',\n",
       " 12.427505493164062,\n",
       " -9.680328369140623,\n",
       " -24.680328369140625]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if infer_kpi table is there\n",
    "cur.execute(\"select * from osc_datacommons_dev.urgentem.infer_kpi LIMIT 5\")\n",
    "cur.fetchall()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0d0a0",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we read inference for KPI sustainability report, 2019 which follows the same format as the output of the KPI Inference model in Demo 2. After reading the report, we automatically infer the data schema from the report, preprocess it and create a table in trino that could be used for visualization in Apache Superset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
