{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train Relevance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset has been [extracted](pdf_text_extraction.ipynb) and [curated](pdf_text_curation.ipynb), we will train the relevance classifier model in this notebook. The model trained is comprised of a transformer model (e.g., BERT) that can be loaded pre-trained on the NQ dataset into the pipeline and then be fine-tuned on the curated data for our specific relevance detection task.\n",
    "\n",
    "Our pipeline includes components that are provided by the FARM library. FARM is a framework which facilitates transfer learning tasks for BERT based models. Documentation for FARM is available here: https://farm.deepset.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/15/2022 01:55:32 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import config\n",
    "import zipfile\n",
    "import pathlib\n",
    "from io import BytesIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "from src.models import FARMTrainer\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "\n",
    "from config_farm_train import (\n",
    "    FileConfig,\n",
    "    ModelConfig,\n",
    "    MLFlowConfig,\n",
    "    TrainingConfig,\n",
    "    TokenizerConfig,\n",
    "    ProcessorConfig,\n",
    ")\n",
    "from farm.infer import Inferencer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting training, parameters for each component of the training pipeline must be set. For this we create `config` objects which hold these parameters. Default values have already been set but they can be easily changed. To do so, you can manually update the parameters in the corresponding config file:\n",
    "\n",
    "`aicoe-osc-demo/notebooks/demo2/config_farm_train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings data files and checkpoints parameters\n",
    "file_config = FileConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the processor component\n",
    "processor_config = ProcessorConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the tokenizer\n",
    "tokenizer_config = TokenizerConfig(config.EXPERIMENT_NAME)\n",
    "# NOTE: specifically for tokenizer, we need to ensure root dir is a string\n",
    "tokenizer_config.root = str(tokenizer_config.root)\n",
    "\n",
    "# Settings for the model\n",
    "model_config = ModelConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "train_config = TrainingConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "mlflow_config = MLFlowConfig(config.EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the value for some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_name: \n",
      " test_cdp2 \n",
      "\n",
      "Data directory: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data \n",
      "\n",
      "Curated dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/curation/esg_TEXT_dataset.csv \n",
      "\n",
      "Split train/validation ratio: \n",
      "0.2 \n",
      "\n",
      "Training dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv \n",
      "\n",
      "Validation dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv \n",
      "\n",
      "Directory where trained model is saved: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/RELEVANCE \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment_name: \\n {file_config.experiment_name} \\n\")\n",
    "print(f\"Data directory: \\n {file_config.data_dir} \\n\")\n",
    "print(f\"Curated dataset path: \\n {file_config.curated_data} \\n\")\n",
    "print(f\"Split train/validation ratio: \\n{file_config.dev_split} \\n\")\n",
    "print(f\"Training dataset path: \\n {file_config.train_filename} \\n\")\n",
    "print(f\"Validation dataset path: \\n {file_config.dev_filename} \\n\")\n",
    "print(f\"Directory where trained model is saved: \\n {file_config.saved_models_dir} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens per example: 128 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max number of tokens per example: {processor_config.max_seq_len} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Use GPU: {train_config.use_cuda} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 1e-05 \n",
      "\n",
      "Number of epochs for fine tuning: 1 \n",
      "\n",
      "Batch size: 1 \n",
      "\n",
      "Perform Cross validation: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Learning_rate: {train_config.learning_rate} \\n\")\n",
    "print(f\"Number of epochs for fine tuning: {train_config.n_epochs} \\n\")\n",
    "print(f\"Batch size: {train_config.batch_size} \\n\")\n",
    "print(f\"Perform Cross validation: {train_config.run_cv} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Pretrained Model\n",
    "\n",
    "We already have a trained relevance classifier on Google's large NQ dataset. We download it and then save it in the following directory: `file_config.saved_models_dir / \"relevance_roberta\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AUTOMATION=1\n"
     ]
    }
   ],
   "source": [
    "%env AUTOMATION = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Automation using Elyra and Kubeflow Pipelines,\n",
    "# set AUTOMATION = 1 as an environment variable\n",
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # extracted pdfs\n",
    "    if not os.path.exists(config.BASE_EXTRACTION_FOLDER):\n",
    "        config.BASE_EXTRACTION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # curated pdfs\n",
    "    if not os.path.exists(config.BASE_CURATION_FOLDER):\n",
    "        config.BASE_CURATION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # processed data\n",
    "    if not os.path.exists(config.BASE_PROCESSED_DATA):\n",
    "        config.BASE_PROCESSED_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # load dir\n",
    "    if not os.path.exists(model_config.load_dir):\n",
    "        pathlib.Path(model_config.load_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download extracted pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_EXTRACTION_S3_PREFIX,\n",
    "        config.BASE_EXTRACTION_FOLDER,\n",
    "    )\n",
    "    # download curated pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_CURATION_S3_PREFIX,\n",
    "        config.BASE_CURATION_FOLDER,\n",
    "    )\n",
    "\n",
    "    # download the pretrained model if needed\n",
    "    model_root = pathlib.Path(model_config.load_dir).parent\n",
    "    model_rel_zip = pathlib.Path(model_root, \"relevance_roberta.zip\")\n",
    "\n",
    "    if not os.path.exists(model_rel_zip):\n",
    "        s3c.download_file_from_s3(\n",
    "            model_rel_zip, config.CHECKPOINT_S3_PREFIX, \"relevance_roberta.zip\"\n",
    "        )\n",
    "\n",
    "    with zipfile.ZipFile(pathlib.Path(model_root, \"relevance_roberta.zip\"), \"r\") as z:\n",
    "        z.extractall(model_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type: \n",
      " Text \n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_config.data_type = \"Text\"\n",
    "print(f\"Data type: \\n {file_config.data_type} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load this model in our pipeline to fine-tune a relevance classifier on our specific ESG curated dataset. For this we have to set the parameter `model_config.load_dir` to be the directory where we saved our first checkpoint. We can check that this is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NQ checkpoint directory: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/relevance_roberta\n"
     ]
    }
   ],
   "source": [
    "print(f\"NQ checkpoint directory: {model_config.load_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune on curated ESG data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the parameters are set, a `FARMTrainer` object can be instantiated by passing all the configuration objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init farm trainer\n",
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    processor_config=processor_config,\n",
    "    model_config=model_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method `run()` to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/15/2022 01:55:38 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/15/2022 01:55:38 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -   Loading train set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv \n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 156 dictionaries to pytorch datasets (chunksize = 6)...\n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -   /|\\  /w\\  /|\\  /|\\  /|\\  /|\\  /w\\\n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -   /'\\  / \\  /'\\  /'\\  /'\\  /'\\  / \\\n",
      "07/15/2022 01:55:38 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv:   0%|          | 0/156 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/15/2022 01:55:39 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/15/2022 01:55:39 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the base year end date for scope 1 emissions?\n",
      " \ttext_b: (C5.1) Provide your base year and base year emissions (Scopes 1 and 2). Scope 1 Base year start January 1 2020 Base year end December 31 2020 Base year emissions (metric tons CO2e) 43311568 Comment\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġend', 'Ġdate', 'Ġfor', 'Ġscope', 'Ġ1', 'Ġemissions', '?']\n",
      " \ttokens_b: ['(', 'C', '5', '.', '1', ')', 'ĠProvide', 'Ġyour', 'Ġbase', 'Ġyear', 'Ġand', 'Ġbase', 'Ġyear', 'Ġemissions', 'Ġ(', 'Sc', 'opes', 'Ġ1', 'Ġand', 'Ġ2', ').', 'ĠScope', 'Ġ1', 'ĠBase', 'Ġyear', 'Ġstart', 'ĠJanuary', 'Ġ1', 'Ġ2020', 'ĠBase', 'Ġyear', 'Ġend', 'ĠDecember', 'Ġ31', 'Ġ2020', 'ĠBase', 'Ġyear', 'Ġemissions', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', ')', 'Ġ433', '115', '68', 'ĠComment']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 253, 1248, 13, 7401, 112, 5035, 116, 2, 2, 1640, 347, 245, 4, 134, 43, 36836, 110, 1542, 76, 8, 1542, 76, 5035, 36, 12645, 18836, 112, 8, 132, 322, 30108, 112, 11056, 76, 386, 644, 112, 2760, 11056, 76, 253, 719, 1105, 2760, 11056, 76, 5035, 36, 5646, 4063, 7741, 6247, 176, 242, 43, 42617, 15314, 4671, 14642, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/15/2022 01:55:39 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 5-0\n",
      "Clear Text: \n",
      " \ttext: What is the target base year?\n",
      " \ttext_b: Intensity metric Other, please specify (Lbs/MWh of CO2) Base year 2005 Intensity figure in base year (metric tons CO2e per unit of activity)\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġbase', 'Ġyear', '?']\n",
      " \ttokens_b: ['Int', 'ensity', 'Ġmetric', 'ĠOther', ',', 'Ġplease', 'Ġspecify', 'Ġ(', 'L', 'bs', '/', 'M', 'Wh', 'Ġof', 'ĠCO', '2', ')', 'ĠBase', 'Ġyear', 'Ġ2005', 'ĠInt', 'ensity', 'Ġfigure', 'Ġin', 'Ġbase', 'Ġyear', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', 'Ġper', 'Ġunit', 'Ġof', 'Ġactivity', ')']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 1542, 76, 116, 2, 2, 22886, 40904, 14823, 1944, 6, 2540, 17151, 36, 574, 4311, 73, 448, 14447, 9, 6247, 176, 43, 11056, 76, 4013, 7299, 40904, 1955, 11, 1542, 76, 36, 5646, 4063, 7741, 6247, 176, 242, 228, 1933, 9, 1940, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv:   4%|▍         | 6/156 [00:01<00:28,  5.19 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv: 100%|██████████| 156/156 [00:05<00:00, 30.09 Dicts/s] \n",
      "07/15/2022 01:55:43 - INFO - farm.data_handler.data_silo -   Loading dev set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 40 dictionaries to pytorch datasets (chunksize = 4)...\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.data_silo -   /|\\  /|\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  /'\\  /'\\  / \\  / \\\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:   0%|          | 0/40 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 1-0\n",
      "Clear Text: \n",
      " \ttext: What is the target reduction amount?\n",
      " \ttext_b: Target year 2025 Targeted reduction from base year (%) 67 Intensity figure in target year (metric tons CO2e per unit of activity)\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġreduction', 'Ġamount', '?']\n",
      " \ttokens_b: ['Target', 'Ġyear', 'Ġ2025', 'ĠTarget', 'ed', 'Ġreduction', 'Ġfrom', 'Ġbase', 'Ġyear', 'Ġ(%)', 'Ġ67', 'ĠInt', 'ensity', 'Ġfigure', 'Ġin', 'Ġtarget', 'Ġyear', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', 'Ġper', 'Ġunit', 'Ġof', 'Ġactivity', ')']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4878, 1280, 116, 2, 2, 41858, 76, 10380, 8506, 196, 4878, 31, 1542, 76, 32965, 5545, 7299, 40904, 1955, 11, 1002, 76, 36, 5646, 4063, 7741, 6247, 176, 242, 228, 1933, 9, 1940, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/15/2022 01:55:44 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0\n",
      "Clear Text: \n",
      " \ttext: What is the target metric in the target year?\n",
      " \ttext_b: Target year 2029 Targeted reduction from base year (%) 42 Covered emissions in target year (metric tons CO2e) [auto-calculated] 2180800\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġmetric', 'Ġin', 'Ġthe', 'Ġtarget', 'Ġyear', '?']\n",
      " \ttokens_b: ['Target', 'Ġyear', 'Ġ20', '29', 'ĠTarget', 'ed', 'Ġreduction', 'Ġfrom', 'Ġbase', 'Ġyear', 'Ġ(%)', 'Ġ42', 'ĠC', 'overed', 'Ġemissions', 'Ġin', 'Ġtarget', 'Ġyear', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', ')', 'Ġ[', 'auto', '-', 'cal', 'culated', ']', 'Ġ218', '08', '00']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 14823, 11, 5, 1002, 76, 116, 2, 2, 41858, 76, 291, 2890, 8506, 196, 4878, 31, 1542, 76, 32965, 3330, 230, 16223, 5035, 11, 1002, 76, 36, 5646, 4063, 7741, 6247, 176, 242, 43, 646, 39545, 12, 11762, 41244, 742, 28405, 3669, 612, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:  10%|█         | 4/40 [00:00<00:05,  6.02 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:  20%|██        | 8/40 [00:01<00:04,  7.06 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv: 100%|██████████| 40/40 [00:01<00:00, 23.61 Dicts/s]\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Examples in train: 156\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Examples in dev  : 40\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   \n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 60.044871794871796\n",
      "07/15/2022 01:55:45 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.11538461538461539\n",
      "07/15/2022 01:55:46 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:55:49 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/15/2022 01:55:55 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/15/2022 01:55:55 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/15/2022 01:55:55 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:55:55 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/relevance_roberta/prediction_head_0.bin\n",
      "07/15/2022 01:55:56 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/15/2022 01:55:56 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/15/2022 01:55:56 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 15.600000000000001, 'num_training_steps': 156}'\n",
      "07/15/2022 01:55:56 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  19%|█▊        | 29/156 [00:02<00:10, 11.55it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 61.39it/s]\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 30 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   loss: 0.2791393980941848\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   acc: 0.95\n",
      "07/15/2022 01:55:59 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.8824    0.9375        17\n",
      "           1     0.9200    1.0000    0.9583        23\n",
      "\n",
      "    accuracy                         0.9500        40\n",
      "   macro avg     0.9600    0.9412    0.9479        40\n",
      "weighted avg     0.9540    0.9500    0.9495        40\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):  38%|███▊      | 60/156 [00:05<00:06, 13.91it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 58.67it/s]\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 60 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   loss: 0.005324578849695172\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   acc: 1.0\n",
      "07/15/2022 01:56:02 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        23\n",
      "\n",
      "    accuracy                         1.0000        40\n",
      "   macro avg     1.0000    1.0000    1.0000        40\n",
      "weighted avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0058):  58%|█████▊    | 90/156 [00:08<00:04, 14.25it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 67.27it/s]\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 90 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   loss: 0.000322593235569002\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   acc: 1.0\n",
      "07/15/2022 01:56:05 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        23\n",
      "\n",
      "    accuracy                         1.0000        40\n",
      "   macro avg     1.0000    1.0000    1.0000        40\n",
      "weighted avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  77%|███████▋  | 120/156 [00:11<00:02, 14.52it/s] \n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 66.34it/s]\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 120 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   loss: 0.0001224135869051679\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   acc: 1.0\n",
      "07/15/2022 01:56:08 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        23\n",
      "\n",
      "    accuracy                         1.0000        40\n",
      "   macro avg     1.0000    1.0000    1.0000        40\n",
      "weighted avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):  96%|█████████▌| 150/156 [00:13<00:00, 13.71it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 67.49it/s]\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   loss: 4.280689074676047e-05\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   acc: 1.0\n",
      "07/15/2022 01:56:10 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        23\n",
      "\n",
      "    accuracy                         1.0000        40\n",
      "   macro avg     1.0000    1.0000    1.0000        40\n",
      "weighted avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 5.1528): 100%|██████████| 156/156 [00:14<00:00, 10.40it/s]\n",
      "Evaluating: 100%|██████████| 40/40 [00:00<00:00, 60.96it/s]\n",
      "07/15/2022 01:56:11 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 40 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:11 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:11 - INFO - farm.eval -   loss: 4.183241637747415e-05\n",
      "07/15/2022 01:56:11 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:12 - INFO - farm.eval -   acc: 1.0\n",
      "07/15/2022 01:56:12 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        17\n",
      "           1     1.0000    1.0000    1.0000        23\n",
      "\n",
      "    accuracy                         1.0000        40\n",
      "   macro avg     1.0000    1.0000    1.0000        40\n",
      "weighted avg     1.0000    1.0000    1.0000        40\n",
      "\n",
      "07/15/2022 01:56:15 - INFO - src.models.farm_trainer -   Trained model saved to /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/RELEVANCE\n",
      "07/15/2022 01:56:15 - INFO - src.models.farm_trainer -   Processor vocabulary saved to /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/RELEVANCE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training process, the model and the processor vocabulary are saved into the directory `file_config.saved_models_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/RELEVANCE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 488352\n",
      "drwxrwsr-x. 2 1000630000 1000630000      4096 Jul  9 08:41 .\n",
      "drwxrwsr-x. 8 1000630000 1000630000      4096 Jul 15 01:52 ..\n",
      "-rw-rw-r--. 1 1000630000 1000630000 498669047 Jul 15 01:56 language_model.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000       562 Jul 15 01:56 language_model_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000    456318 Jul 15 01:56 merges.txt\n",
      "-rw-rw-r--. 1 1000630000 1000630000      7489 Jul 15 01:56 prediction_head_0.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000       321 Jul 15 01:56 prediction_head_0_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       789 Jul 15 01:56 processor_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       772 Jul 15 01:56 special_tokens_map.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000       240 Jul 15 01:56 tokenizer_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000    898822 Jul 15 01:56 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -al $file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better estimate the performance of the model on new data, it is recommended to perform k-folds cross validation (CV). CV works as follows:\n",
    "\n",
    "- Split the entire data randomly into k folds (usually 5 to 10)\n",
    "- Fit the model using the K — 1 folds and validate the model using the remaining Kth fold and save the scores\n",
    "- Repeat until every K-fold serve as the test set and average the saved scores\n",
    "\n",
    "`FARMTrainer` includes this features. To perform 3-fold CV proceed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config.run_cv = True\n",
    "train_config.xval_folds = 2\n",
    "train_config.n_epochs = 1\n",
    "train_config.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "farm_trainer = FARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/15/2022 01:56:16 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/15/2022 01:56:16 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -   Loading train set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv \n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 156 dictionaries to pytorch datasets (chunksize = 6)...\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -   /|\\  /w\\  /|\\  /|\\  /|\\  /|\\  /w\\\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -   /'\\  / \\  /'\\  /'\\  /'\\  /'\\  / \\\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv:   0%|          | 0/156 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 5-0\n",
      "Clear Text: \n",
      " \ttext: What is the target base year?\n",
      " \ttext_b: Intensity metric Other, please specify (Lbs/MWh of CO2) Base year 2005 Intensity figure in base year (metric tons CO2e per unit of activity)\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġbase', 'Ġyear', '?']\n",
      " \ttokens_b: ['Int', 'ensity', 'Ġmetric', 'ĠOther', ',', 'Ġplease', 'Ġspecify', 'Ġ(', 'L', 'bs', '/', 'M', 'Wh', 'Ġof', 'ĠCO', '2', ')', 'ĠBase', 'Ġyear', 'Ġ2005', 'ĠInt', 'ensity', 'Ġfigure', 'Ġin', 'Ġbase', 'Ġyear', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', 'Ġper', 'Ġunit', 'Ġof', 'Ġactivity', ')']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 1542, 76, 116, 2, 2, 22886, 40904, 14823, 1944, 6, 2540, 17151, 36, 574, 4311, 73, 448, 14447, 9, 6247, 176, 43, 11056, 76, 4013, 7299, 40904, 1955, 11, 1542, 76, 36, 5646, 4063, 7741, 6247, 176, 242, 228, 1933, 9, 1940, 43, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/15/2022 01:56:17 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 3-0\n",
      "Clear Text: \n",
      " \ttext: What is the target reduction amount?\n",
      " \ttext_b: ii) Example: If we are unable to innovate effectively or utilise technological advancements to make our products more sustainable, we may cease to be competitive, impacting sales and future growth. We are working to address this risk in our household cleaning and laundry portfolio through ‘Clean Future’, which is removing black carbon ingredients from our products in place of recycled or renewable carbon through: - Using bio-science and industrial biotechnology to produce highly efficient cleaning ingredients from sustainably sourced biomass, such as the rhamnolipids (a surfactant) we are using in our hand dishwash detergent in Chile and Vietnam or new high-performing bio-enzymes. - Turning non-recyclable plastic waste destined for landfill or incineration into biodegradable cleaning and fragrance chemicals. - Turning CO2 from industrial emissions into useful chemicals and \n",
      " \ttext_classification_label: 0\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġreduction', 'Ġamount', '?']\n",
      " \ttokens_b: ['ii', ')', 'ĠExample', ':', 'ĠIf', 'Ġwe', 'Ġare', 'Ġunable', 'Ġto', 'Ġinnovate', 'Ġeffectively', 'Ġor', 'Ġutil', 'ise', 'Ġtechnological', 'Ġadvancements', 'Ġto', 'Ġmake', 'Ġour', 'Ġproducts', 'Ġmore', 'Ġsustainable', ',', 'Ġwe', 'Ġmay', 'Ġcease', 'Ġto', 'Ġbe', 'Ġcompetitive', ',', 'Ġimpacting', 'Ġsales', 'Ġand', 'Ġfuture', 'Ġgrowth', '.', 'ĠWe', 'Ġare', 'Ġworking', 'Ġto', 'Ġaddress', 'Ġthis', 'Ġrisk', 'Ġin', 'Ġour', 'Ġhousehold', 'Ġcleaning', 'Ġand', 'Ġlaundry', 'Ġportfolio', 'Ġthrough', 'ĠâĢ', 'ĺ', 'Clean', 'ĠFuture', 'âĢ', 'Ļ', ',', 'Ġwhich', 'Ġis', 'Ġremoving', 'Ġblack', 'Ġcarbon', 'Ġingredients', 'Ġfrom', 'Ġour', 'Ġproducts', 'Ġin', 'Ġplace', 'Ġof', 'Ġrecycled', 'Ġor', 'Ġrenewable', 'Ġcarbon', 'Ġthrough', ':', 'Ġ-', 'ĠUsing', 'Ġbio', '-', 'science', 'Ġand', 'Ġindustrial', 'Ġbi', 'otechnology', 'Ġto', 'Ġproduce', 'Ġhighly', 'Ġefficient', 'Ġcleaning', 'Ġingredients', 'Ġfrom', 'Ġsustain', 'ably', 'Ġsourced', 'Ġbiomass', ',', 'Ġsuch', 'Ġas', 'Ġthe', 'Ġr', 'ham', 'n', 'ol', 'ip', 'ids', 'Ġ(', 'a', 'Ġsurf', 'act', 'ant', ')', 'Ġwe', 'Ġare', 'Ġusing', 'Ġin', 'Ġour']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 4878, 1280, 116, 2, 2, 4132, 43, 42516, 35, 318, 52, 32, 3276, 7, 26818, 4296, 50, 14258, 1496, 9874, 23931, 7, 146, 84, 785, 55, 5068, 6, 52, 189, 14342, 7, 28, 2695, 6, 18081, 647, 8, 499, 434, 4, 166, 32, 447, 7, 1100, 42, 810, 11, 84, 6028, 8143, 8, 16937, 2819, 149, 44, 711, 40827, 7543, 17, 27, 6, 61, 16, 8201, 909, 4363, 7075, 31, 84, 785, 11, 317, 9, 18505, 50, 8741, 4363, 149, 35, 111, 8630, 10709, 12, 33749, 8, 2683, 4003, 17634, 7, 2592, 2200, 5693, 8143, 7075, 31, 9844, 4735, 16898, 36782, 6, 215, 25, 5, 910, 1908, 282, 1168, 1588, 7823, 36, 102, 11641, 7257, 927, 43, 52, 32, 634, 11, 84, 2]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [0]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_train_split.csv: 100%|██████████| 156/156 [00:05<00:00, 30.47 Dicts/s]\n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -   Loading dev set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv\n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -   Got ya 7 parallel workers to convert 40 dictionaries to pytorch datasets (chunksize = 4)...\n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -    0    0    0    0    0    0    0 \n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -   /|\\  /|\\  /w\\  /|\\  /w\\  /w\\  /w\\\n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -   /'\\  /'\\  /'\\  /'\\  /'\\  / \\  / \\\n",
      "07/15/2022 01:56:22 - INFO - farm.data_handler.data_silo -               \n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:   0%|          | 0/40 [00:00<?, ? Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/15/2022 01:56:23 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/15/2022 01:56:23 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 2-0\n",
      "Clear Text: \n",
      " \ttext: Provide your base year and base year scope2 (location-based) emissions.\n",
      " \ttext_b: Scope 2 (location-based) Base year start January 1, 2009 Base year end December 31, 2009 Base year emissions (metric tons CO2e) 1,060,153 Comment\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['Prov', 'ide', 'Ġyour', 'Ġbase', 'Ġyear', 'Ġand', 'Ġbase', 'Ġyear', 'Ġscope', '2', 'Ġ(', 'location', '-', 'based', ')', 'Ġemissions', '.']\n",
      " \ttokens_b: ['Scope', 'Ġ2', 'Ġ(', 'location', '-', 'based', ')', 'ĠBase', 'Ġyear', 'Ġstart', 'ĠJanuary', 'Ġ1', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġend', 'ĠDecember', 'Ġ31', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġemissions', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', ')', 'Ġ1', ',', '060', ',', '153', 'ĠComment']\n",
      "Features: \n",
      " \tinput_ids: [0, 35746, 1949, 110, 1542, 76, 8, 1542, 76, 7401, 176, 36, 41829, 12, 805, 43, 5035, 4, 2, 2, 45190, 132, 36, 41829, 12, 805, 43, 11056, 76, 386, 644, 112, 6, 2338, 11056, 76, 253, 719, 1105, 6, 2338, 11056, 76, 5035, 36, 5646, 4063, 7741, 6247, 176, 242, 43, 112, 6, 37143, 6, 27982, 14642, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/15/2022 01:56:23 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 2-0\n",
      "Clear Text: \n",
      " \ttext: Provide your base year and base year scope2 (location-based) emissions.\n",
      " \ttext_b: Scope 2 (location-based) Base year start January 1, 2009 Base year end December 31, 2009 Base year emissions (metric tons CO2e) 1,060,153 Comment\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['Prov', 'ide', 'Ġyour', 'Ġbase', 'Ġyear', 'Ġand', 'Ġbase', 'Ġyear', 'Ġscope', '2', 'Ġ(', 'location', '-', 'based', ')', 'Ġemissions', '.']\n",
      " \ttokens_b: ['Scope', 'Ġ2', 'Ġ(', 'location', '-', 'based', ')', 'ĠBase', 'Ġyear', 'Ġstart', 'ĠJanuary', 'Ġ1', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġend', 'ĠDecember', 'Ġ31', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġemissions', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', ')', 'Ġ1', ',', '060', ',', '153', 'ĠComment']\n",
      "Features: \n",
      " \tinput_ids: [0, 35746, 1949, 110, 1542, 76, 8, 1542, 76, 7401, 176, 36, 41829, 12, 805, 43, 5035, 4, 2, 2, 45190, 132, 36, 41829, 12, 805, 43, 11056, 76, 386, 644, 112, 6, 2338, 11056, 76, 253, 719, 1105, 6, 2338, 11056, 76, 5035, 36, 5646, 4063, 7741, 6247, 176, 242, 43, 112, 6, 37143, 6, 27982, 14642, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:  10%|█         | 4/40 [00:00<00:03, 10.38 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv:  20%|██        | 8/40 [00:00<00:03,  8.90 Dicts/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/kpi_val_split.csv: 100%|██████████| 40/40 [00:01<00:00, 22.49 Dicts/s]\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Examples in train: 156\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Examples in dev  : 40\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   \n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 60.044871794871796\n",
      "07/15/2022 01:56:25 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.11538461538461539\n",
      "07/15/2022 01:56:25 - INFO - src.models.farm_trainer -   ############ Crossvalidation: Fold 0 ############\n",
      "07/15/2022 01:56:25 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:56:28 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/15/2022 01:56:31 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/15/2022 01:56:31 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/15/2022 01:56:31 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:56:31 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/relevance_roberta/prediction_head_0.bin\n",
      "07/15/2022 01:56:32 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/15/2022 01:56:32 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/15/2022 01:56:32 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 1.0, 'num_training_steps': 10}'\n",
      "07/15/2022 01:56:32 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0010): 100%|██████████| 10/10 [00:00<00:00, 10.16it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 49.20it/s]\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 10 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   loss: 0.23998324859089085\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   acc: 0.9489795918367347\n",
      "07/15/2022 01:56:33 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9231    0.9796    0.9505        49\n",
      "           1     0.9783    0.9184    0.9474        49\n",
      "\n",
      "    accuracy                         0.9490        98\n",
      "   macro avg     0.9507    0.9490    0.9489        98\n",
      "weighted avg     0.9507    0.9490    0.9489        98\n",
      "\n",
      "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 47.51it/s]\n",
      "07/15/2022 01:56:33 - INFO - src.models.farm_trainer -   ############ Crossvalidation: Fold 1 ############\n",
      "07/15/2022 01:56:33 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:56:37 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/15/2022 01:56:40 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/15/2022 01:56:40 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/15/2022 01:56:40 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:56:40 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/relevance_roberta/prediction_head_0.bin\n",
      "07/15/2022 01:56:41 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
      "07/15/2022 01:56:41 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/15/2022 01:56:41 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 1.0, 'num_training_steps': 10}'\n",
      "07/15/2022 01:56:41 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0052): 100%|██████████| 10/10 [00:01<00:00,  9.72it/s]\n",
      "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 45.24it/s]\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 10 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   loss: 0.3349256466228363\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   task_name: text_classification\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   acc: 0.9387755102040817\n",
      "07/15/2022 01:56:42 - INFO - farm.eval -   report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9074    0.9800    0.9423        50\n",
      "           1     0.9773    0.8958    0.9348        48\n",
      "\n",
      "    accuracy                         0.9388        98\n",
      "   macro avg     0.9423    0.9379    0.9385        98\n",
      "weighted avg     0.9416    0.9388    0.9386        98\n",
      "\n",
      "Evaluating: 100%|██████████| 13/13 [00:00<00:00, 49.53it/s]\n",
      "07/15/2022 01:56:42 - INFO - src.models.farm_trainer -   ############ RESULT_CV -- 2 folds ############\n",
      "07/15/2022 01:56:42 - INFO - src.models.farm_trainer -   Mean F1:  94.1, std F1: 0.006\n",
      "07/15/2022 01:56:42 - INFO - src.models.farm_trainer -   Mean recall:  97.8, std recall: 0.000\n",
      "07/15/2022 01:56:42 - INFO - src.models.farm_trainer -   Mean accuracy:  94.4, std accuracy; 0.005\n",
      "07/15/2022 01:56:42 - INFO - src.models.farm_trainer -   Mean precision:  90.7, std  precision: 0.011\n"
     ]
    }
   ],
   "source": [
    "farm_trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** CV mode does not save a checkpoint, it is only used for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Metrics\n",
    "\n",
    "In this section, we will quantify the performance of the fine tuned model on our dataset. Specifically, we will calculate the precision, recall, and f1-score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the target metric in the target year?</td>\n",
       "      <td>Target year 2029 Targeted reduction from base ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the target reduction amount?</td>\n",
       "      <td>Target year 2025 Targeted reduction from base ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>Provide your base year and base year scope2 (l...</td>\n",
       "      <td>Scope 2 (location-based) Base year start Janua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the base year start date for scope 2 (...</td>\n",
       "      <td>Scope 2 (market-based) Base year start January...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the End Date of the CDP report published?</td>\n",
       "      <td>Bayer AG - Climate Change 2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  \\\n",
       "154      1      What is the target metric in the target year?   \n",
       "167      1               What is the target reduction amount?   \n",
       "32       1  Provide your base year and base year scope2 (l...   \n",
       "115      1  What is the base year start date for scope 2 (...   \n",
       "59       1  What is the End Date of the CDP report published?   \n",
       "\n",
       "                                                text_b  \n",
       "154  Target year 2029 Targeted reduction from base ...  \n",
       "167  Target year 2025 Targeted reduction from base ...  \n",
       "32   Scope 2 (location-based) Base year start Janua...  \n",
       "115  Scope 2 (market-based) Base year start January...  \n",
       "59                      Bayer AG - Climate Change 2021  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test set\n",
    "test_data = pd.read_csv(file_config.dev_filename, index_col=0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/15/2022 01:56:43 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "07/15/2022 01:56:46 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/15/2022 01:56:46 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
      "07/15/2022 01:56:46 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
      "07/15/2022 01:56:46 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/RELEVANCE/prediction_head_0.bin\n",
      "07/15/2022 01:56:46 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/15/2022 01:56:46 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "07/15/2022 01:56:46 - INFO - farm.utils -   device: cpu n_gpu: 0, distributed training: False, automatic mixed precision training: None\n",
      "07/15/2022 01:56:46 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "07/15/2022 01:56:46 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "07/15/2022 01:56:46 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "07/15/2022 01:56:46 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "07/15/2022 01:56:46 - INFO - farm.infer -               \n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "07/15/2022 01:56:46 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/15/2022 01:56:46 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 2-0\n",
      "Clear Text: \n",
      " \ttext: Provide your base year and base year scope2 (location-based) emissions.\n",
      " \ttext_b: Scope 2 (location-based) Base year start January 1, 2009 Base year end December 31, 2009 Base year emissions (metric tons CO2e) 1,060,153 Comment\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['Prov', 'ide', 'Ġyour', 'Ġbase', 'Ġyear', 'Ġand', 'Ġbase', 'Ġyear', 'Ġscope', '2', 'Ġ(', 'location', '-', 'based', ')', 'Ġemissions', '.']\n",
      " \ttokens_b: ['Scope', 'Ġ2', 'Ġ(', 'location', '-', 'based', ')', 'ĠBase', 'Ġyear', 'Ġstart', 'ĠJanuary', 'Ġ1', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġend', 'ĠDecember', 'Ġ31', ',', 'Ġ2009', 'ĠBase', 'Ġyear', 'Ġemissions', 'Ġ(', 'met', 'ric', 'Ġtons', 'ĠCO', '2', 'e', ')', 'Ġ1', ',', '060', ',', '153', 'ĠComment']\n",
      "Features: \n",
      " \tinput_ids: [0, 35746, 1949, 110, 1542, 76, 8, 1542, 76, 7401, 176, 36, 41829, 12, 805, 43, 5035, 4, 2, 2, 45190, 132, 36, 41829, 12, 805, 43, 11056, 76, 386, 644, 112, 6, 2338, 11056, 76, 253, 719, 1105, 6, 2338, 11056, 76, 5035, 36, 5646, 4063, 7741, 6247, 176, 242, 43, 112, 6, 37143, 6, 27982, 14642, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "07/15/2022 01:56:46 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 3-0\n",
      "Clear Text: \n",
      " \ttext: What is the base year start date for scope 2 (market-based) emissions?\n",
      " \ttext_b: Scope 2 (market-based) Base year start January 1 2020 Base year end December 31 2020 Base year emissions\n",
      " \ttext_classification_label: 1\n",
      "Tokenized: \n",
      " \ttokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġstart', 'Ġdate', 'Ġfor', 'Ġscope', 'Ġ2', 'Ġ(', 'market', '-', 'based', ')', 'Ġemissions', '?']\n",
      " \ttokens_b: ['Scope', 'Ġ2', 'Ġ(', 'market', '-', 'based', ')', 'ĠBase', 'Ġyear', 'Ġstart', 'ĠJanuary', 'Ġ1', 'Ġ2020', 'ĠBase', 'Ġyear', 'Ġend', 'ĠDecember', 'Ġ31', 'Ġ2020', 'ĠBase', 'Ġyear', 'Ġemissions']\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 386, 1248, 13, 7401, 132, 36, 2989, 12, 805, 43, 5035, 116, 2, 2, 45190, 132, 36, 2989, 12, 805, 43, 11056, 76, 386, 644, 112, 2760, 11056, 76, 253, 719, 1105, 2760, 11056, 76, 5035, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \ttext_classification_label_ids: [1]\n",
      "_____________________________________________________\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Inferencing Samples:   0%|          | 0/1 [00:00<?, ? Batches/s]/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.8/site-packages/transformers/tokenization_utils.py:458: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
      "  warnings.warn(\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:05<00:00,  5.79s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.49s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.80s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.30s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.60s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.59s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.41s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:04<00:00,  4.38s/ Batches]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:03<00:00,  3.70s/ Batches]\n"
     ]
    }
   ],
   "source": [
    "# get predictions from current model\n",
    "model = Inferencer.load(file_config.saved_models_dir)\n",
    "\n",
    "result = model.inference_from_file(file_config.dev_filename)\n",
    "results = [d for r in result for d in r[\"predictions\"]]\n",
    "preds = [int(r[\"label\"]) for r in results]\n",
    "\n",
    "test_data[\"pred\"] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evalute performance\n",
    "groups = test_data.groupby(\"text\")\n",
    "scores = {}\n",
    "for group, data in groups:\n",
    "    pred = data.pred\n",
    "    true = data.label\n",
    "    scores[group] = {}\n",
    "    scores[group][\"accuracy\"] = accuracy_score(true, pred)\n",
    "    scores[group][\"f1_score\"] = f1_score(true, pred)\n",
    "    scores[group][\"recall_score\"] = recall_score(true, pred)\n",
    "    scores[group][\"precision_score\"] = precision_score(true, pred)\n",
    "    scores[group][\"support\"] = len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did you have an emissions target that was active in the reporting year?</th>\n",
       "      <th>Provide your base year and base year scope 1 emissions.</th>\n",
       "      <th>Provide your base year and base year scope2 (location-based) emissions.</th>\n",
       "      <th>Provide your base year and base year scope2 (market-based) emissions.</th>\n",
       "      <th>What is the % change in absolute Scope 3 emissions?</th>\n",
       "      <th>What is the End Date of the CDP report published?</th>\n",
       "      <th>What is the Start Date of the CDP report published?</th>\n",
       "      <th>What is the absolute target name?</th>\n",
       "      <th>What is the base year end date for scope 1 emissions?</th>\n",
       "      <th>What is the base year start date for scope 2 (location-based) emissions?</th>\n",
       "      <th>What is the base year start date for scope 2 (market-based) emissions?</th>\n",
       "      <th>What is the company name?</th>\n",
       "      <th>What is the intensity figure in reporting year?</th>\n",
       "      <th>What is the target base year value?</th>\n",
       "      <th>What is the target metric in the target year?</th>\n",
       "      <th>What is the target metric?</th>\n",
       "      <th>What is the target reduction amount?</th>\n",
       "      <th>What is the target scope?</th>\n",
       "      <th>What is the target year?</th>\n",
       "      <th>What is the year the target was set?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Did you have an emissions target that was active in the reporting year?  \\\n",
       "accuracy                                                       1.0                         \n",
       "f1_score                                                       1.0                         \n",
       "recall_score                                                   1.0                         \n",
       "precision_score                                                1.0                         \n",
       "support                                                        1.0                         \n",
       "\n",
       "                 Provide your base year and base year scope 1 emissions.  \\\n",
       "accuracy                                                       1.0         \n",
       "f1_score                                                       1.0         \n",
       "recall_score                                                   1.0         \n",
       "precision_score                                                1.0         \n",
       "support                                                        3.0         \n",
       "\n",
       "                 Provide your base year and base year scope2 (location-based) emissions.  \\\n",
       "accuracy                                                       1.0                         \n",
       "f1_score                                                       1.0                         \n",
       "recall_score                                                   1.0                         \n",
       "precision_score                                                1.0                         \n",
       "support                                                        4.0                         \n",
       "\n",
       "                 Provide your base year and base year scope2 (market-based) emissions.  \\\n",
       "accuracy                                                       1.0                       \n",
       "f1_score                                                       1.0                       \n",
       "recall_score                                                   1.0                       \n",
       "precision_score                                                1.0                       \n",
       "support                                                        4.0                       \n",
       "\n",
       "                 What is the % change in absolute Scope 3 emissions?  \\\n",
       "accuracy                                                       1.0     \n",
       "f1_score                                                       0.0     \n",
       "recall_score                                                   0.0     \n",
       "precision_score                                                0.0     \n",
       "support                                                        1.0     \n",
       "\n",
       "                 What is the End Date of the CDP report published?  \\\n",
       "accuracy                                                       1.0   \n",
       "f1_score                                                       1.0   \n",
       "recall_score                                                   1.0   \n",
       "precision_score                                                1.0   \n",
       "support                                                        2.0   \n",
       "\n",
       "                 What is the Start Date of the CDP report published?  \\\n",
       "accuracy                                                       1.0     \n",
       "f1_score                                                       1.0     \n",
       "recall_score                                                   1.0     \n",
       "precision_score                                                1.0     \n",
       "support                                                        1.0     \n",
       "\n",
       "                 What is the absolute target name?  \\\n",
       "accuracy                                       1.0   \n",
       "f1_score                                       1.0   \n",
       "recall_score                                   1.0   \n",
       "precision_score                                1.0   \n",
       "support                                        2.0   \n",
       "\n",
       "                 What is the base year end date for scope 1 emissions?  \\\n",
       "accuracy                                                       1.0       \n",
       "f1_score                                                       1.0       \n",
       "recall_score                                                   1.0       \n",
       "precision_score                                                1.0       \n",
       "support                                                        2.0       \n",
       "\n",
       "                 What is the base year start date for scope 2 (location-based) emissions?  \\\n",
       "accuracy                                                       1.0                          \n",
       "f1_score                                                       1.0                          \n",
       "recall_score                                                   1.0                          \n",
       "precision_score                                                1.0                          \n",
       "support                                                        1.0                          \n",
       "\n",
       "                 What is the base year start date for scope 2 (market-based) emissions?  \\\n",
       "accuracy                                                       1.0                        \n",
       "f1_score                                                       1.0                        \n",
       "recall_score                                                   1.0                        \n",
       "precision_score                                                1.0                        \n",
       "support                                                        2.0                        \n",
       "\n",
       "                 What is the company name?  \\\n",
       "accuracy                               1.0   \n",
       "f1_score                               0.0   \n",
       "recall_score                           0.0   \n",
       "precision_score                        0.0   \n",
       "support                                1.0   \n",
       "\n",
       "                 What is the intensity figure in reporting year?  \\\n",
       "accuracy                                                     1.0   \n",
       "f1_score                                                     0.0   \n",
       "recall_score                                                 0.0   \n",
       "precision_score                                              0.0   \n",
       "support                                                      1.0   \n",
       "\n",
       "                 What is the target base year value?  \\\n",
       "accuracy                                         1.0   \n",
       "f1_score                                         1.0   \n",
       "recall_score                                     1.0   \n",
       "precision_score                                  1.0   \n",
       "support                                          2.0   \n",
       "\n",
       "                 What is the target metric in the target year?  \\\n",
       "accuracy                                                   1.0   \n",
       "f1_score                                                   1.0   \n",
       "recall_score                                               1.0   \n",
       "precision_score                                            1.0   \n",
       "support                                                    1.0   \n",
       "\n",
       "                 What is the target metric?  \\\n",
       "accuracy                                1.0   \n",
       "f1_score                                1.0   \n",
       "recall_score                            1.0   \n",
       "precision_score                         1.0   \n",
       "support                                 4.0   \n",
       "\n",
       "                 What is the target reduction amount?  \\\n",
       "accuracy                                          1.0   \n",
       "f1_score                                          1.0   \n",
       "recall_score                                      1.0   \n",
       "precision_score                                   1.0   \n",
       "support                                           4.0   \n",
       "\n",
       "                 What is the target scope?  What is the target year?  \\\n",
       "accuracy                               1.0                       1.0   \n",
       "f1_score                               1.0                       0.0   \n",
       "recall_score                           1.0                       0.0   \n",
       "precision_score                        1.0                       0.0   \n",
       "support                                1.0                       1.0   \n",
       "\n",
       "                 What is the year the target was set?  \n",
       "accuracy                                          1.0  \n",
       "f1_score                                          0.0  \n",
       "recall_score                                      0.0  \n",
       "precision_score                                   0.0  \n",
       "support                                           2.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kpi wise performance metrics\n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results locally\n",
    "if not os.getenv(\"AUTOMATION\"):\n",
    "    scores_df.to_csv(file_config.model_performance_metrics_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to s3\n",
    "\n",
    "Great, we have a fine tuned model at this point. We will now save this model as well as its performance metrics to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'EXHXTGM92TWNCAN6',\n",
       "  'HostId': '+FvhWwfEf4g3045iSQ6d0XSPtBk25bdI56w9xDIvP1jujBz8juySC1A2JT6zb0APcEUfEomxpdI=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '+FvhWwfEf4g3045iSQ6d0XSPtBk25bdI56w9xDIvP1jujBz8juySC1A2JT6zb0APcEUfEomxpdI=',\n",
       "   'x-amz-request-id': 'EXHXTGM92TWNCAN6',\n",
       "   'date': 'Fri, 15 Jul 2022 01:57:28 GMT',\n",
       "   'etag': '\"772812863cfff927dea06a877a4399f4\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"772812863cfff927dea06a877a4399f4\"'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload performance files to s3\n",
    "s3c.upload_df_to_s3(\n",
    "    scores_df,\n",
    "    s3_prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    s3_key=\"relevance_scores.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BytesIO()\n",
    "with zipfile.ZipFile(buffer, 'a') as z:\n",
    "    for dirname, _, files in os.walk(file_config.saved_models_dir):\n",
    "        for f in files:\n",
    "            f_path = os.path.join(dirname, f)\n",
    "            with open (f_path, 'rb') as file_content:\n",
    "                z.writestr(f\"RELEVANCE/{f}\", file_content.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'PC58HQPZR7B0Z5ZW',\n",
       "  'HostId': 'sDtv4RsMG25OZ8h7vTW8fIyxs6ghVQfvjS91UY/1jfmr8P+v6eMfikm9T1rkgKHjEoAaYxG/0Nk=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'sDtv4RsMG25OZ8h7vTW8fIyxs6ghVQfvjS91UY/1jfmr8P+v6eMfikm9T1rkgKHjEoAaYxG/0Nk=',\n",
       "   'x-amz-request-id': 'PC58HQPZR7B0Z5ZW',\n",
       "   'date': 'Fri, 15 Jul 2022 01:57:30 GMT',\n",
       "   'etag': '\"0447a2f82b2bd63f003a9ca15e1b59c6\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"0447a2f82b2bd63f003a9ca15e1b59c6\"'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.seek(0)\n",
    "# upload model to s3\n",
    "s3c._upload_bytes(\n",
    "    buffer_bytes=buffer,\n",
    "    prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    key=\"RELEVANCE.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we developed a model that can be used for finding relevant paragraphs for a KPI question, given a list of paragraphs from climate report PDFs. With this model in place, we can go ahead to training the kpi extraction model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
