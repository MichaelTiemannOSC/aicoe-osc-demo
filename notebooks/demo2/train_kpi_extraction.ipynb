{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI Extraction\n",
    "\n",
    "At this point in the training pipeline, we have developed notebooks to curate the ESG data with annotations, and then training a relevance classifier on it to determine if a given paragraph is relevant to answering given a KPI question. In this notebook, we will train a model that, given a relevant paragraph and a KPI question, extracts the precise answer to that question from the paragraph.\n",
    "\n",
    "The KPI extraction model that we will be training for this task is a Question-Answering (QA) model. For training such models, the input data is generally required to be present in a specific format, such as that in the SQuAD dataset. SQuAD is a public dataset for the Question-Answering task. So the first section of this notebook deals with getting the ESG data curated in a SQuAD-like format. And then the subsequent sections consume this re-formatted data for training the model. \n",
    "\n",
    "The model training related classes being used in this notebook include components that are provided by the FARM library. FARM is a framework which facilitates transfer learning tasks for BERT based models. Documentation for FARM is available here: https://farm.deepset.ai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/16/2022 14:51:15 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "\n",
    "from farm.infer import QAInferencer\n",
    "from farm.evaluation import squad_evaluation\n",
    "from farm.data_handler.utils import write_squad_predictions\n",
    "\n",
    "from src.models.qa_farm_trainer import QAFARMTrainer\n",
    "from src.data.s3_communication import S3Communication, S3FileType\n",
    "from src.components.preprocessing.kpi_inference_curator import TextKPIInferenceCurator\n",
    "\n",
    "import config\n",
    "from config_qa_farm_train import (\n",
    "    QAFileConfig,\n",
    "    QATokenizerConfig,\n",
    "    QAProcessorConfig,\n",
    "    QAModelConfig,\n",
    "    QATrainingConfig,\n",
    "    QAMLFlowConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init s3 connector\n",
    "s3c = S3Communication(\n",
    "    s3_endpoint_url=os.getenv(\"S3_ENDPOINT\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\"),\n",
    "    s3_bucket=os.getenv(\"S3_BUCKET\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kpi_id</th>\n",
       "      <th>question</th>\n",
       "      <th>sectors</th>\n",
       "      <th>add_year</th>\n",
       "      <th>kpi_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>What is the company name?</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>What is the Start Date of the CDP report publi...</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>What is the End Date of the CDP report published?</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>What is the currency used for all financial in...</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Did you have an emissions target that was acti...</td>\n",
       "      <td>OG, CM, CU</td>\n",
       "      <td>False</td>\n",
       "      <td>TEXT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   kpi_id                                           question     sectors  \\\n",
       "0     1.0                          What is the company name?  OG, CM, CU   \n",
       "1     2.0  What is the Start Date of the CDP report publi...  OG, CM, CU   \n",
       "2     3.0  What is the End Date of the CDP report published?  OG, CM, CU   \n",
       "3     4.0  What is the currency used for all financial in...  OG, CM, CU   \n",
       "4     5.0  Did you have an emissions target that was acti...  OG, CM, CU   \n",
       "\n",
       "   add_year kpi_category  \n",
       "0     False         TEXT  \n",
       "1     False         TEXT  \n",
       "2     False         TEXT  \n",
       "3     False         TEXT  \n",
       "4     False         TEXT  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpi_df = s3c.download_df_from_s3(\n",
    "    f\"{config.EXPERIMENT_NAME}/kpi_mapping\",\n",
    "    \"kpi_mapping.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    "    header=0,\n",
    ")\n",
    "kpi_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Data in SQuAD Format\n",
    "\n",
    "The following code will curate the data and output them as SQuAD-like format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When running in Automation using Elyra and Kubeflow Pipelines,\n",
    "# set AUTOMATION = 1 as an environment variable\n",
    "if os.getenv(\"AUTOMATION\"):\n",
    "    # extracted pdfs\n",
    "    if not os.path.exists(config.BASE_EXTRACTION_FOLDER):\n",
    "        config.BASE_EXTRACTION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(config.BASE_ANNOTATION_FOLDER):\n",
    "        config.BASE_ANNOTATION_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(config.BASE_INFER_RELEVANCE_FOLDER):\n",
    "        config.BASE_INFER_RELEVANCE_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # processed data\n",
    "    if not os.path.exists(config.BASE_PROCESSED_DATA):\n",
    "        config.BASE_PROCESSED_DATA.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # output squad\n",
    "    if not os.path.exists(config.TextKPIInferenceCurator_kwargs['output_squad_folder']):\n",
    "        pathlib.Path(config.TextKPIInferenceCurator_kwargs['output_squad_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # download extracted pdfs from s3\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_EXTRACTION_S3_PREFIX,\n",
    "        config.BASE_EXTRACTION_FOLDER,\n",
    "    )\n",
    "\n",
    "    # download the annoatation files\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_ANNOTATION_S3_PREFIX,\n",
    "        config.BASE_ANNOTATION_FOLDER,\n",
    "    )\n",
    "    # download the relevance infer files\n",
    "    s3c.download_files_in_prefix_to_dir(\n",
    "        config.BASE_INFER_RELEVANCE_S3_PREFIX,\n",
    "        config.BASE_INFER_RELEVANCE_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run data curation with default settings\n",
    "tkpi = TextKPIInferenceCurator(\n",
    "    **config.TextKPIInferenceCurator_kwargs,\n",
    "    kpi_df=kpi_df,\n",
    "    columns_to_read=config.TRAIN_KPI_INFERENCE_COLUMNS_TO_READ,\n",
    ")\n",
    "train_squad, val_squad = tkpi.curate(**config.CurateConfig().__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the data in SQuAD format, which is ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpi_train.json\t      reference_kpi_13-07-2022.csv\n",
      "kpi_train_split.json  reference_kpi_15-07-2022.csv\n",
      "kpi_val_split.json    reference_kpi_16-07-2022.csv\n"
     ]
    }
   ],
   "source": [
    "# see that the data has been reformatted and placed in the output folder\n",
    "output_dir = str(config.TextKPIInferenceCurator_kwargs['output_squad_folder'])\n",
    "!ls $output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Now that we have the data in an appropriate format, we will train a QA model (or rather, fine tune a pretrained QA model) in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Training Parameters  \n",
    "Before start training, parameters for each component of the training pipeline must be set. For this we create `config` objects which hold these parameters. Default values have already been set but they can be easily changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings data files and checkpoints parameters\n",
    "file_config = QAFileConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the processor component\n",
    "processor_config = QAProcessorConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the tokenizer\n",
    "tokenizer_config = QATokenizerConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for the model\n",
    "model_config = QAModelConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "train_config = QATrainingConfig(config.EXPERIMENT_NAME)\n",
    "\n",
    "# Settings for training\n",
    "mlflow_config = QAMLFlowConfig(config.EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed data\n",
    "pred_dir = pathlib.Path(file_config.dev_predictions_filename).parent\n",
    "if not os.path.exists(pred_dir):\n",
    "    pred_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters can be changed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.EXPERIMENT_NAME = \"test-training-pipeline\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we advise that you manually update the parameters in the corresponding config file:\n",
    "\n",
    "`./config_qa_farm_trainer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment_name: \n",
      " test_cdp2 \n",
      "\n",
      "Data directory: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data \n",
      "\n",
      "Curated dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train.json \n",
      "\n",
      "Split train/validation ratio: \n",
      "0.2 \n",
      "\n",
      "Training dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train_split.json \n",
      "\n",
      "Validation dataset path: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_val_split.json \n",
      "\n",
      "Directory where trained model is saved: \n",
      " /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/KPI_EXTRACTION \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Experiment_name: \\n {file_config.experiment_name} \\n\")\n",
    "print(f\"Data directory: \\n {file_config.data_dir} \\n\")\n",
    "print(f\"Curated dataset path: \\n {file_config.curated_data} \\n\")\n",
    "print(f\"Split train/validation ratio: \\n{file_config.dev_split} \\n\")\n",
    "print(f\"Training dataset path: \\n {file_config.train_filename} \\n\")\n",
    "print(f\"Validation dataset path: \\n {file_config.dev_filename} \\n\")\n",
    "print(f\"Directory where trained model is saved: \\n {file_config.saved_models_dir} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens per example: 384 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max number of tokens per example: {processor_config.max_seq_len} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: True \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Use GPU: {train_config.use_cuda} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning_rate: 2e-05 \n",
      "\n",
      "Number of epochs for fine tuning: 1 \n",
      "\n",
      "Batch size: 4 \n",
      "\n",
      "Perform Cross validation: False \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Learning_rate: {train_config.learning_rate} \\n\")\n",
    "print(f\"Number of epochs for fine tuning: {train_config.n_epochs} \\n\")\n",
    "print(f\"Batch size: {train_config.batch_size} \\n\")\n",
    "print(f\"Perform Cross validation: {train_config.run_cv} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune on Curated Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fine tune the model on the curated ESG data. In the following section, a a `QAFARMTrainer` object can be instantiated by passing all the configuration objects. This object defines the model, which is essentially a bert-based model with extra dense layers for the question answering task. The weights of this model are initialized from the pretrained model on SQuAD dataset. In addition to the model, some other necessary components such as the Tokenizer and Processor will also be loaded. These components are used to create features from the input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to convert root directory location from PosixPath to str\n",
    "# otherwise transformers lib is unable to serialize and save the tokenizer\n",
    "tokenizer_config.root = str(tokenizer_config.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init trainer / fine-tuner\n",
    "farm_trainer = QAFARMTrainer(\n",
    "    file_config=file_config,\n",
    "    tokenizer_config=tokenizer_config,\n",
    "    model_config=model_config,\n",
    "    processor_config=processor_config,\n",
    "    training_config=train_config,\n",
    "    mlflow_config=mlflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the method `run()` to start training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** For the first time, loading the model will take a little longer, for download the checkpoints. The model will be cached after that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/16/2022 14:51:34 - INFO - src.models.qa_farm_trainer -   Loading the /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train.json data and splitting to train and val...\n",
      "07/16/2022 14:51:34 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: True\n",
      "07/16/2022 14:51:35 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/16/2022 14:51:35 - INFO - farm.data_handler.data_silo -   \n",
      "Loading data into the data silo ... \n",
      "              ______\n",
      "               |o  |   !\n",
      "   __          |:`_|---'-.\n",
      "  |__|______.-/ _ \\-----.|       \n",
      " (o)(o)------'\\ _ /     ( )      \n",
      " \n",
      "07/16/2022 14:51:35 - INFO - farm.data_handler.data_silo -   Loading train set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train_split.json \n",
      "07/16/2022 14:51:35 - INFO - farm.data_handler.data_silo -   Multiprocessing disabled, using a single worker to convert 644dictionaries to pytorch datasets.\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train_split.json:   0%|          | 0/644 [00:00<?, ? Dicts/s]07/16/2022 14:51:48 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/16/2022 14:51:48 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 369-4-0\n",
      "Clear Text: \n",
      " \tpassage_text: this represents process emissions related to pg&e's natural gas operations during 2020 \n",
      " \tquestion_text: What is the base year start date for scope 1 emissions?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['this', 'Ġrepresents', 'Ġprocess', 'Ġemissions', 'Ġrelated', 'Ġto', 'Ġpg', '&', 'e', \"'s\", 'Ġnatural', 'Ġgas', 'Ġoperations', 'Ġduring', 'Ġ2020']\n",
      " \tpassage_offsets: [0, 5, 16, 24, 34, 42, 45, 47, 48, 49, 52, 60, 64, 75, 82]\n",
      " \tpassage_start_of_word: [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1]\n",
      " \tquestion_tokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġstart', 'Ġdate', 'Ġfor', 'Ġscope', 'Ġ1', 'Ġemissions', '?']\n",
      " \tquestion_offsets: [0, 5, 8, 12, 17, 22, 28, 33, 37, 43, 45, 54]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 5, 16, 24, 34, 42, 45, 47, 48, 49, 52, 60, 64, 75, 82]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 386, 1248, 13, 7401, 112, 5035, 116, 2, 2, 9226, 3372, 609, 5035, 1330, 7, 47194, 947, 242, 18, 1632, 1123, 1414, 148, 2760, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [369, 4, 0]\n",
      " \tseq_2_start_t: 15\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/16/2022 14:51:48 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 532-13-0\n",
      "Clear Text: \n",
      " \tpassage_text: reason for change change from previous year includes emission reduction initiatives discussed in 4.3b. intensity figure and % change is based on scope 1 emissions from current reporting year 2020 and previous year 2019 – generation only. scope 1 emissions for fleet fuel has not been included in the 2019 calculation, as this is our first reporting year.\n",
      " \tquestion_text: What is the base year start date for scope 2 (location-based) emissions?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['reason', 'Ġfor', 'Ġchange', 'Ġchange', 'Ġfrom', 'Ġprevious', 'Ġyear', 'Ġincludes', 'Ġemission', 'Ġreduction', 'Ġinitiatives', 'Ġdiscussed', 'Ġin', 'Ġ4', '.', '3', 'b', '.', 'Ġintensity', 'Ġfigure', 'Ġand', 'Ġ%', 'Ġchange', 'Ġis', 'Ġbased', 'Ġon', 'Ġscope', 'Ġ1', 'Ġemissions', 'Ġfrom', 'Ġcurrent', 'Ġreporting', 'Ġyear', 'Ġ2020', 'Ġand', 'Ġprevious', 'Ġyear', 'Ġ2019', 'ĠâĢĵ', 'Ġgeneration', 'Ġonly', '.', 'Ġscope', 'Ġ1', 'Ġemissions', 'Ġfor', 'Ġfleet', 'Ġfuel', 'Ġhas', 'Ġnot', 'Ġbeen', 'Ġincluded', 'Ġin', 'Ġthe', 'Ġ2019', 'Ġcalculation', ',', 'Ġas', 'Ġthis', 'Ġis', 'Ġour', 'Ġfirst', 'Ġreporting', 'Ġyear', '.']\n",
      " \tpassage_offsets: [0, 7, 11, 18, 25, 30, 39, 44, 53, 62, 72, 84, 94, 97, 98, 99, 100, 101, 103, 113, 120, 124, 126, 133, 136, 142, 145, 151, 153, 163, 168, 176, 186, 191, 196, 200, 209, 214, 219, 221, 232, 236, 238, 244, 246, 256, 260, 266, 271, 275, 279, 284, 293, 296, 300, 305, 316, 318, 321, 326, 329, 333, 339, 349, 353]\n",
      " \tpassage_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tquestion_tokens: ['What', 'Ġis', 'Ġthe', 'Ġbase', 'Ġyear', 'Ġstart', 'Ġdate', 'Ġfor', 'Ġscope', 'Ġ2', 'Ġ(', 'location', '-', 'based', ')', 'Ġemissions', '?']\n",
      " \tquestion_offsets: [0, 5, 8, 12, 17, 22, 28, 33, 37, 43, 45, 46, 54, 55, 60, 62, 71]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 7, 11, 18, 25, 30, 39, 44, 53, 62, 72, 84, 94, 97, 98, 99, 100, 101, 103, 113, 120, 124, 126, 133, 136, 142, 145, 151, 153, 163, 168, 176, 186, 191, 196, 200, 209, 214, 219, 221, 232, 236, 238, 244, 246, 256, 260, 266, 271, 275, 279, 284, 293, 296, 300, 305, 316, 318, 321, 326, 329, 333, 339, 349, 353]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1542, 76, 386, 1248, 13, 7401, 132, 36, 41829, 12, 805, 43, 5035, 116, 2, 2, 41995, 13, 464, 464, 31, 986, 76, 1171, 22679, 4878, 5287, 3373, 11, 204, 4, 246, 428, 4, 10603, 1955, 8, 7606, 464, 16, 716, 15, 7401, 112, 5035, 31, 595, 2207, 76, 2760, 8, 986, 76, 954, 126, 2706, 129, 4, 7401, 112, 5035, 13, 7620, 2423, 34, 45, 57, 1165, 11, 5, 954, 21586, 6, 25, 42, 16, 84, 78, 2207, 76, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [532, 13, 0]\n",
      " \tseq_2_start_t: 20\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_train_split.json:  20%|██        | 129/644 [00:13<00:52,  9.89 Dicts/s]\n",
      "07/16/2022 14:51:48 - INFO - farm.data_handler.data_silo -   Loading dev set from: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_val_split.json\n",
      "07/16/2022 14:51:48 - INFO - farm.data_handler.data_silo -   Multiprocessing disabled, using a single worker to convert 161dictionaries to pytorch datasets.\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_val_split.json:   0%|          | 0/161 [00:00<?, ? Dicts/s]07/16/2022 14:51:51 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 123-2-0\n",
      "Clear Text: \n",
      " \tpassage_text: percentage of scope 3, category 1 tco2e from purchased feedstock\n",
      " \tquestion_text: What were your organization’s gross global Scope 1 emissions in metric tons CO2e?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['percent', 'age', 'Ġof', 'Ġscope', 'Ġ3', ',', 'Ġcategory', 'Ġ1', 'Ġt', 'co', '2', 'e', 'Ġfrom', 'Ġpurchased', 'Ġfeed', 'stock']\n",
      " \tpassage_offsets: [0, 7, 11, 14, 20, 21, 23, 32, 34, 35, 37, 38, 40, 45, 55, 59]\n",
      " \tpassage_start_of_word: [1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0]\n",
      " \tquestion_tokens: ['What', 'Ġwere', 'Ġyour', 'Ġorganization', 'âĢ', 'Ļ', 's', 'Ġgross', 'Ġglobal', 'ĠScope', 'Ġ1', 'Ġemissions', 'Ġin', 'Ġmetric', 'Ġtons', 'ĠCO', '2', 'e', '?']\n",
      " \tquestion_offsets: [0, 5, 10, 15, 27, 29, 30, 30, 36, 43, 49, 51, 61, 64, 71, 76, 78, 79, 80]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 7, 11, 14, 20, 21, 23, 32, 34, 35, 37, 38, 40, 45, 55, 59]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 58, 110, 1651, 17, 27, 29, 4200, 720, 30108, 112, 5035, 11, 14823, 7741, 6247, 176, 242, 116, 2, 2, 13566, 1580, 9, 7401, 155, 6, 4120, 112, 326, 876, 176, 242, 31, 3584, 3993, 9607, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [123, 2, 0]\n",
      " \tseq_2_start_t: 22\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 90-33-0\n",
      "Clear Text: \n",
      " \tpassage_text: scope 1 emissions intensity metric tons co2e per gwh 548.93\n",
      " \tquestion_text: Break down your total gross global Scope 2 emissions by country/region.\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['scope', 'Ġ1', 'Ġemissions', 'Ġintensity', 'Ġmetric', 'Ġtons', 'Ġco', '2', 'e', 'Ġper', 'Ġg', 'wh', 'Ġ5', '48', '.', '93']\n",
      " \tpassage_offsets: [0, 6, 8, 18, 28, 35, 40, 42, 43, 45, 49, 50, 53, 54, 56, 57]\n",
      " \tpassage_start_of_word: [1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      " \tquestion_tokens: ['Break', 'Ġdown', 'Ġyour', 'Ġtotal', 'Ġgross', 'Ġglobal', 'ĠScope', 'Ġ2', 'Ġemissions', 'Ġby', 'Ġcountry', '/', 'region', '.']\n",
      " \tquestion_offsets: [0, 6, 11, 16, 22, 28, 35, 41, 43, 53, 56, 63, 64, 70]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 6, 8, 18, 28, 35, 40, 42, 43, 45, 49, 50, 53, 54, 56, 57]\n",
      "Features: \n",
      " \tinput_ids: [0, 39539, 159, 110, 746, 4200, 720, 30108, 132, 5035, 30, 247, 73, 37140, 4, 2, 2, 39576, 112, 5035, 10603, 14823, 7741, 1029, 176, 242, 228, 821, 11613, 195, 3818, 4, 6478, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [90, 33, 0]\n",
      " \tseq_2_start_t: 17\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "Preprocessing Dataset /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_val_split.json:  20%|██        | 33/161 [00:02<00:10, 12.24 Dicts/s]\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   No test set is being loaded\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Examples in train: 7014\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Examples in dev  : 1733\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Examples in test : 0\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   \n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     384\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 94.38066723695466\n",
      "07/16/2022 14:51:51 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.02837182777302538\n",
      "07/16/2022 14:52:05 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [1024, 2]\n",
      "07/16/2022 14:52:14 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
      "\t We guess it's an *ENGLISH* model ... \n",
      "\t If not: Init the language model by supplying the 'language' param.\n",
      "07/16/2022 14:52:18 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 2e-05}'\n",
      "07/16/2022 14:52:18 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
      "07/16/2022 14:52:18 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 21.900000000000002, 'num_training_steps': 219}'\n",
      "07/16/2022 14:52:18 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):   3%|▎         | 50/1754 [00:15<08:29,  3.35it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:30, 10.59it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:20, 10.58it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:11, 10.54it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 50 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   loss: 0.15389503720515257\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 14:53:15 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):   6%|▌         | 100/1754 [01:11<07:43,  3.57it/s] \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.55it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.55it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.55it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.58it/s]\u001b[A\n",
      "07/16/2022 14:54:10 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:54:10 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:54:10 - INFO - farm.eval -   loss: 0.17045284345255676\n",
      "07/16/2022 14:54:10 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:54:11 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:54:11 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:54:11 - INFO - farm.eval -   top_n_accuracy: 0.9924593967517401\n",
      "07/16/2022 14:54:11 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):   9%|▊         | 150/1754 [02:06<07:25,  3.60it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.60it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.59it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.59it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.61it/s]\u001b[A\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   loss: 0.16386510354408765\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   top_n_accuracy: 0.9924593967517401\n",
      "07/16/2022 14:55:06 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0050):  11%|█▏        | 200/1754 [03:02<07:13,  3.58it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.64it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.57it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.59it/s]\u001b[A\n",
      "07/16/2022 14:56:01 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:56:01 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:56:01 - INFO - farm.eval -   loss: 0.1023421534602447\n",
      "07/16/2022 14:56:01 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:56:01 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:56:02 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:56:02 - INFO - farm.eval -   top_n_accuracy: 0.9959396751740139\n",
      "07/16/2022 14:56:02 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0536):  14%|█▍        | 250/1754 [03:57<07:16,  3.45it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.49it/s]\u001b[A\n",
      "Evaluating:  49%|████▊     | 211/434 [00:20<00:21, 10.54it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 317/434 [00:30<00:11, 10.55it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 250 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   loss: 0.4096658777507894\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   EM: 0.988399071925754\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   f1: 0.988399071925754\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   top_n_accuracy: 0.9976798143851509\n",
      "07/16/2022 14:56:57 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):  17%|█▋        | 300/1754 [04:53<06:51,  3.53it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.54it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 213/434 [00:20<00:20, 10.58it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.57it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   loss: 0.1886546191198886\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   EM: 0.990139211136891\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   f1: 0.990139211136891\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   top_n_accuracy: 0.9930394431554525\n",
      "07/16/2022 14:57:53 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  20%|█▉        | 350/1754 [05:48<06:32,  3.58it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.55it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.51it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:11, 10.54it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.55it/s]\u001b[A\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 350 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   loss: 0.11989710175501321\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   top_n_accuracy: 0.9965197215777262\n",
      "07/16/2022 14:58:48 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0005):  23%|██▎       | 400/1754 [06:44<06:18,  3.58it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:30, 10.58it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:20, 10.58it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.55it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.58it/s]\u001b[A\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   loss: 0.12925533844009998\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   top_n_accuracy: 0.9936194895591647\n",
      "07/16/2022 14:59:44 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0008):  26%|██▌       | 450/1754 [07:40<06:16,  3.46it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.57it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:20, 10.58it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:11, 10.52it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 450 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   loss: 0.06943157412712578\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   top_n_accuracy: 0.9976798143851509\n",
      "07/16/2022 15:00:40 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):  29%|██▊       | 500/1754 [08:35<05:51,  3.56it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:30, 10.59it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:20, 10.59it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.56it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 500 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   loss: 0.10013660823823417\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   top_n_accuracy: 0.9965197215777262\n",
      "07/16/2022 15:01:35 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0018):  31%|███▏      | 550/1754 [09:31<05:36,  3.57it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.62it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.57it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.55it/s]\u001b[A\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 550 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   loss: 0.1300435055582529\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   EM: 0.9878190255220418\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   f1: 0.9878190255220418\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   top_n_accuracy: 0.9976798143851509\n",
      "07/16/2022 15:02:31 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0000):  34%|███▍      | 600/1754 [10:27<05:20,  3.60it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.56it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.57it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.58it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   loss: 0.20165205120075233\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   EM: 0.988399071925754\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   f1: 0.988399071925754\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   top_n_accuracy: 0.9907192575406032\n",
      "07/16/2022 15:03:27 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  37%|███▋      | 650/1754 [11:22<05:18,  3.47it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.51it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.55it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.56it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.58it/s]\u001b[A\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 650 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   loss: 0.17997385520744366\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   top_n_accuracy: 0.9918793503480279\n",
      "07/16/2022 15:04:22 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0009):  40%|███▉      | 700/1754 [12:18<04:58,  3.54it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.57it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.57it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:11, 10.54it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.57it/s]\u001b[A\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 700 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   loss: 0.10852432427782753\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   top_n_accuracy: 0.9930394431554525\n",
      "07/16/2022 15:05:18 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  43%|████▎     | 750/1754 [13:14<04:39,  3.59it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.62it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.55it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.55it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.59it/s]\u001b[A\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 750 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   loss: 0.12485834282928507\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   top_n_accuracy: 0.9930394431554525\n",
      "07/16/2022 15:06:13 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0161):  46%|████▌     | 800/1754 [14:09<04:25,  3.60it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.50it/s]\u001b[A\n",
      "Evaluating:  49%|████▊     | 211/434 [00:20<00:21, 10.55it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 317/434 [00:30<00:11, 10.54it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.56it/s]\u001b[A\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 800 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   loss: 0.10337422828233558\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   EM: 0.9907192575406032\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   f1: 0.9907192575406032\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:07:09 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  48%|████▊     | 850/1754 [15:05<04:20,  3.47it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.44it/s]\u001b[A\n",
      "Evaluating:  49%|████▊     | 211/434 [00:20<00:21, 10.52it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 317/434 [00:30<00:11, 10.48it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.51it/s]\u001b[A\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 850 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   loss: 0.1874663225463519\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   EM: 0.9895591647331786\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   f1: 0.9896751740139211\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   top_n_accuracy: 0.9959396751740139\n",
      "07/16/2022 15:08:05 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  51%|█████▏    | 900/1754 [16:00<04:02,  3.53it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.52it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.51it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:11, 10.53it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.55it/s]\u001b[A\n",
      "07/16/2022 15:09:00 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 900 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:09:00 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   loss: 0.1773231915913418\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   EM: 0.9849187935034803\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   f1: 0.9849187935034803\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:09:01 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0016):  54%|█████▍    | 950/1754 [16:56<03:44,  3.58it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:30, 10.60it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.47it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 316/434 [00:30<00:11, 10.40it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.40it/s]\u001b[A\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 950 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   loss: 0.14436056816050824\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   EM: 0.984338747099768\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   f1: 0.984338747099768\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   top_n_accuracy: 0.9970997679814385\n",
      "07/16/2022 15:09:57 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  57%|█████▋    | 1000/1754 [17:53<03:30,  3.58it/s] \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.43it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 210/434 [00:20<00:21, 10.42it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 315/434 [00:30<00:11, 10.36it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.36it/s]\u001b[A\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   loss: 0.1591830221870006\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   EM: 0.990139211136891\n",
      "07/16/2022 15:10:53 - INFO - farm.eval -   f1: 0.990139211136891\n",
      "07/16/2022 15:10:54 - INFO - farm.eval -   top_n_accuracy: 0.9936194895591647\n",
      "07/16/2022 15:10:54 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.3913):  60%|█████▉    | 1050/1754 [18:49<03:25,  3.43it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 104/434 [00:10<00:32, 10.30it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 209/434 [00:20<00:21, 10.37it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 314/434 [00:30<00:11, 10.36it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:42<00:00, 10.33it/s]\u001b[A\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1050 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   loss: 0.18329686048381252\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   EM: 0.9889791183294664\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   f1: 0.9889791183294664\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   top_n_accuracy: 0.9924593967517401\n",
      "07/16/2022 15:11:50 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  63%|██████▎   | 1100/1754 [19:46<03:06,  3.51it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.52it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.55it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 318/434 [00:30<00:10, 10.56it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.59it/s]\u001b[A\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1100 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   loss: 0.1790156299671544\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   top_n_accuracy: 0.9912993039443155\n",
      "07/16/2022 15:12:46 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  66%|██████▌   | 1150/1754 [20:41<02:47,  3.60it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.63it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.62it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 321/434 [00:30<00:10, 10.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.63it/s]\u001b[A\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1150 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   loss: 0.18831037010675628\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   EM: 0.9878190255220418\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   f1: 0.9878190255220418\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   top_n_accuracy: 0.9912993039443155\n",
      "07/16/2022 15:13:41 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  68%|██████▊   | 1200/1754 [21:37<02:33,  3.62it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  25%|██▍       | 107/434 [00:10<00:30, 10.65it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 214/434 [00:20<00:20, 10.63it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 321/434 [00:30<00:10, 10.62it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.64it/s]\u001b[A\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1200 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   loss: 0.150153981120956\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:14:36 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:14:37 - INFO - farm.eval -   top_n_accuracy: 0.9947795823665894\n",
      "07/16/2022 15:14:37 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0012):  71%|███████▏  | 1250/1754 [22:32<02:26,  3.45it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.40it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 210/434 [00:20<00:21, 10.45it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 315/434 [00:30<00:11, 10.38it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:42<00:00, 10.33it/s]\u001b[A\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1250 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   loss: 0.13797478422746104\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   EM: 0.9849187935034803\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   f1: 0.9849187935034803\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   top_n_accuracy: 0.9970997679814385\n",
      "07/16/2022 15:15:33 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0009):  74%|███████▍  | 1300/1754 [23:29<02:10,  3.48it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 104/434 [00:10<00:31, 10.36it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 209/434 [00:20<00:21, 10.44it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 314/434 [00:30<00:11, 10.42it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.46it/s]\u001b[A\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1300 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   loss: 0.13313203728010806\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   EM: 0.9878190255220418\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   f1: 0.9878190255220418\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   top_n_accuracy: 0.9970997679814385\n",
      "07/16/2022 15:16:29 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.1722):  77%|███████▋  | 1350/1754 [24:25<01:56,  3.47it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.51it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 213/434 [00:20<00:20, 10.58it/s]\u001b[A\n",
      "Evaluating:  74%|███████▎  | 320/434 [00:30<00:10, 10.59it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:40<00:00, 10.61it/s]\u001b[A\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1350 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   loss: 0.34793634468035806\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   EM: 0.9599767981438515\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   f1: 0.9599767981438515\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   top_n_accuracy: 0.9936194895591647\n",
      "07/16/2022 15:17:25 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  80%|███████▉  | 1400/1754 [25:21<01:39,  3.55it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 104/434 [00:10<00:31, 10.34it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 208/434 [00:20<00:21, 10.30it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 311/434 [00:30<00:11, 10.30it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:42<00:00, 10.32it/s]\u001b[A\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1400 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   loss: 0.7142301121918351\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   EM: 0.8538283062645011\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   f1: 0.854343903067801\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   top_n_accuracy: 0.9924593967517401\n",
      "07/16/2022 15:18:22 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  83%|████████▎ | 1450/1754 [26:18<01:29,  3.41it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 104/434 [00:10<00:32, 10.31it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 208/434 [00:20<00:21, 10.31it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 312/434 [00:30<00:11, 10.27it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.36it/s]\u001b[A\n",
      "07/16/2022 15:19:18 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1450 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:19:18 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:19:18 - INFO - farm.eval -   loss: 0.5552142059526004\n",
      "07/16/2022 15:19:18 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:19:18 - INFO - farm.eval -   EM: 0.9408352668213457\n",
      "07/16/2022 15:19:19 - INFO - farm.eval -   f1: 0.9409319412219644\n",
      "07/16/2022 15:19:19 - INFO - farm.eval -   top_n_accuracy: 0.9930394431554525\n",
      "07/16/2022 15:19:19 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  86%|████████▌ | 1500/1754 [27:14<01:13,  3.46it/s]  \n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.51it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.28it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 315/434 [00:30<00:11, 10.29it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.33it/s]\u001b[A\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1500 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   loss: 0.21092616535177205\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   EM: 0.9767981438515081\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   f1: 0.9767981438515081\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   top_n_accuracy: 0.9918793503480279\n",
      "07/16/2022 15:20:15 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0001):  88%|████████▊ | 1550/1754 [28:11<00:58,  3.50it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 106/434 [00:10<00:31, 10.51it/s]\u001b[A\n",
      "Evaluating:  49%|████▉     | 212/434 [00:20<00:21, 10.39it/s]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 316/434 [00:30<00:11, 10.39it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.42it/s]\u001b[A\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1550 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   loss: 0.11161529955171227\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   top_n_accuracy: 0.994199535962877\n",
      "07/16/2022 15:21:12 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0002):  91%|█████████ | 1600/1754 [29:07<00:42,  3.61it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.42it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 210/434 [00:20<00:21, 10.35it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 314/434 [00:30<00:11, 10.33it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.36it/s]\u001b[A\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1600 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   loss: 0.10165588610211201\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   EM: 0.988399071925754\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   f1: 0.988399071925754\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   top_n_accuracy: 0.9965197215777262\n",
      "07/16/2022 15:22:08 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.2900):  94%|█████████▍| 1650/1754 [30:04<00:30,  3.39it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.46it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 210/434 [00:20<00:21, 10.33it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 313/434 [00:30<00:11, 10.30it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.38it/s]\u001b[A\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1650 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   loss: 0.09885716842502502\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   EM: 0.988399071925754\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   f1: 0.988399071925754\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:23:05 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0003):  97%|█████████▋| 1700/1754 [31:01<00:15,  3.52it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 104/434 [00:10<00:31, 10.39it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 208/434 [00:20<00:21, 10.32it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 312/434 [00:30<00:11, 10.32it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:42<00:00, 10.33it/s]\u001b[A\n",
      "07/16/2022 15:24:01 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1700 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:24:01 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   loss: 0.09004831763491705\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   EM: 0.988399071925754\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   f1: 0.988399071925754\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:24:02 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0006): 100%|█████████▉| 1750/1754 [31:57<00:01,  3.59it/s]\n",
      "Evaluating:   0%|          | 0/434 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:  24%|██▍       | 105/434 [00:10<00:31, 10.43it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 210/434 [00:20<00:21, 10.40it/s]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 314/434 [00:30<00:11, 10.36it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.36it/s]\u001b[A\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 1750 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   loss: 0.08788902238650873\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:24:58 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "Train epoch 0/0 (Cur. train loss: 0.0005): 100%|██████████| 1754/1754 [32:41<00:00,  1.12s/it]\n",
      "Evaluating: 100%|██████████| 434/434 [00:41<00:00, 10.35it/s]\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 434 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   \n",
      " _________ question_answering _________\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   loss: 0.08788902238650873\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   task_name: question_answering\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   EM: 0.9872389791183295\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   f1: 0.9872389791183295\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   top_n_accuracy: 0.9953596287703016\n",
      "07/16/2022 15:25:41 - INFO - farm.eval -   report: \n",
      " Not Implemented\n",
      "07/16/2022 15:25:41 - INFO - src.models.qa_farm_trainer -   Extended Results:\n",
      "07/16/2022 15:25:41 - INFO - src.models.qa_farm_trainer -   {'TN': 1702, 'FP': 6, 'FN': 16, 'TP': 0, 'relaxed_f1_answerable': 0.0, 'em_answerable': 0.0, 'f1_answerable': 0.0}\n",
      "07/16/2022 15:25:53 - INFO - src.models.farm_trainer -   Trained model saved to /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/KPI_EXTRACTION\n",
      "07/16/2022 15:25:53 - INFO - src.models.farm_trainer -   Processor vocabulary saved to /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/KPI_EXTRACTION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9872389791183295"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start training\n",
    "farm_trainer.run(metric=\"f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training process, the model and the processor vocabulary are saved into the directory `file_config.saved_models_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1389660\n",
      "drwxrwsr-x. 2 1000630000 1000630000       4096 Jul  9 09:49 .\n",
      "drwxrwsr-x. 8 1000630000 1000630000       4096 Jul 15 01:52 ..\n",
      "-rw-rw-r--. 1 1000630000 1000630000 1421605239 Jul 16 15:25 language_model.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000        572 Jul 16 15:25 language_model_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000     456318 Jul 16 15:25 merges.txt\n",
      "-rw-rw-r--. 1 1000630000 1000630000       9473 Jul 16 15:25 prediction_head_0.bin\n",
      "-rw-rw-r--. 1 1000630000 1000630000        405 Jul 16 15:25 prediction_head_0_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000        881 Jul 16 15:25 processor_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000        150 Jul 16 15:25 special_tokens_map.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000        628 Jul 16 15:25 tokenizer_config.json\n",
      "-rw-rw-r--. 1 1000630000 1000630000     898822 Jul 16 15:25 vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls -al $file_config.saved_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the developement dataset at `file_config.dev_filename`. This dataset has not been seen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/data/squad/kpi_val_split.json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_config.dev_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference on Samples\n",
    "\n",
    "At this point we have a fine tuned model that can be used to extract answers to KPI questions! Let's use the saved model and test it on some real examples (that the model has not seen before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/16/2022 15:25:54 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "07/16/2022 15:26:04 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
      "07/16/2022 15:26:04 - WARNING - farm.modeling.prediction_head -   Some unused parameters are passed to the QuestionAnsweringHead. Might not be a problem. Params: {\"training\": false, \"num_labels\": 2, \"ph_output_type\": \"per_token_squad\", \"model_type\": \"span_classification\", \"label_tensor_name\": \"question_answering_label_ids\", \"label_list\": [\"start_token\", \"end_token\"], \"metric\": \"squad\", \"name\": \"QuestionAnsweringHead\"}\n",
      "07/16/2022 15:26:04 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [1024, 2]\n",
      "07/16/2022 15:26:04 - INFO - farm.modeling.prediction_head -   Loading prediction head from /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/models/KPI_EXTRACTION/prediction_head_0.bin\n",
      "07/16/2022 15:26:04 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'RobertaTokenizer'\n",
      "07/16/2022 15:26:04 - INFO - farm.data_handler.processor -   Initialized processor without tasks. Supply `metric` and `label_list` to the constructor for using the default task or add a custom task later via processor.add_task()\n",
      "07/16/2022 15:26:04 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
      "07/16/2022 15:26:05 - INFO - farm.infer -   Got ya 7 parallel workers to do inference ...\n",
      "07/16/2022 15:26:05 - INFO - farm.infer -    0    0    0    0    0    0    0 \n",
      "07/16/2022 15:26:05 - INFO - farm.infer -   /w\\  /w\\  /w\\  /w\\  /w\\  /w\\  /w\\\n",
      "07/16/2022 15:26:05 - INFO - farm.infer -   /'\\  / \\  /'\\  /'\\  / \\  / \\  /'\\\n",
      "07/16/2022 15:26:05 - INFO - farm.infer -               \n",
      "07/16/2022 15:26:05 - WARNING - farm.infer -   QAInferencer always has task_type='question_answering' even if another value is provided to Inferencer.load() or QAInferencer()\n",
      "07/16/2022 15:26:05 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/16/2022 15:26:05 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0-0\n",
      "Clear Text: \n",
      " \tpassage_text: the paris agreement on climate change drafted in 2015 aims to reduce worldwide emissions of greenhouse\n",
      "gases to a level intended to limit a rise in global temperatures to below 2 degrees or, better still,\n",
      "to below 1.5 degrees. verbund’s target of reducing greenhouse gas emissions by 90% measured beginning from\n",
      "the basis year 2011 5 million tonnes co2e until 2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions\n",
      "for energy and air travel. the science based targets initiative validated this goal as science-based in october 2016,\n",
      "i.e. it meets global standards. according to current planning, the target can be achieved.\n",
      "however, if the grid operator requires higher generation volumes\n",
      "\n",
      " \tquestion_text: What is the target year for climate commitment?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['the', 'Ġpar', 'is', 'Ġagreement', 'Ġon', 'Ġclimate', 'Ġchange', 'Ġdrafted', 'Ġin', 'Ġ2015', 'Ġaims', 'Ġto', 'Ġreduce', 'Ġworldwide', 'Ġemissions', 'Ġof', 'Ġgreenhouse', 'Ġgases', 'Ġto', 'Ġa', 'Ġlevel', 'Ġintended', 'Ġto', 'Ġlimit', 'Ġa', 'Ġrise', 'Ġin', 'Ġglobal', 'Ġtemperatures', 'Ġto', 'Ġbelow', 'Ġ2', 'Ġdegrees', 'Ġor', ',', 'Ġbetter', 'Ġstill', ',', 'Ġto', 'Ġbelow', 'Ġ1', '.', '5', 'Ġdegrees', '.', 'Ġverb', 'und', 'âĢ', 'Ļ', 's', 'Ġtarget', 'Ġof', 'Ġreducing', 'Ġgreenhouse', 'Ġgas', 'Ġemissions', 'Ġby', 'Ġ90', '%', 'Ġmeasured', 'Ġbeginning', 'Ġfrom', 'Ġthe', 'Ġbasis', 'Ġyear', 'Ġ2011', 'Ġ5', 'Ġmillion', 'Ġtonnes', 'Ġco', '2', 'e', 'Ġuntil', 'Ġ2021', 'Ġincludes', 'Ġscope', 'Ġ1', ',', 'Ġscope', 'Ġ2', 'Ġmarket', '-', 'Ġbased', 'Ġand', 'Ġparts', 'Ġof', 'Ġscope', 'Ġ3', 'Ġemissions', 'Ġfor', 'Ġenergy', 'Ġand', 'Ġair', 'Ġtravel', '.', 'Ġthe', 'Ġscience', 'Ġbased', 'Ġtargets', 'Ġinitiative', 'Ġvalidated', 'Ġthis', 'Ġgoal', 'Ġas', 'Ġscience', '-', 'based', 'Ġin', 'Ġoct', 'ober', 'Ġ2016', ',', 'Ġi', '.', 'e', '.', 'Ġit', 'Ġmeets', 'Ġglobal', 'Ġstandards', '.', 'Ġaccording', 'Ġto', 'Ġcurrent', 'Ġplanning', ',', 'Ġthe', 'Ġtarget', 'Ġcan', 'Ġbe', 'Ġachieved', '.', 'Ġhowever', ',', 'Ġif', 'Ġthe', 'Ġgrid', 'Ġoperator', 'Ġrequires', 'Ġhigher', 'Ġgeneration', 'Ġvolumes']\n",
      " \tpassage_offsets: [0, 4, 7, 10, 20, 23, 31, 38, 46, 49, 54, 59, 62, 69, 79, 89, 92, 103, 109, 112, 114, 120, 129, 132, 138, 140, 145, 148, 155, 168, 171, 177, 179, 187, 189, 191, 198, 203, 205, 208, 214, 215, 216, 218, 225, 227, 231, 234, 236, 237, 237, 244, 247, 256, 267, 271, 281, 284, 286, 288, 297, 307, 312, 316, 322, 327, 332, 334, 342, 349, 351, 352, 354, 360, 365, 374, 380, 381, 383, 389, 391, 397, 399, 405, 409, 415, 418, 424, 426, 436, 440, 447, 451, 455, 461, 463, 467, 475, 481, 489, 500, 510, 515, 520, 523, 530, 531, 537, 540, 543, 548, 552, 554, 555, 556, 557, 559, 562, 568, 575, 584, 586, 596, 599, 607, 615, 617, 621, 628, 632, 635, 643, 645, 652, 654, 657, 661, 666, 675, 684, 691, 702]\n",
      " \tpassage_start_of_word: [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tquestion_tokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġyear', 'Ġfor', 'Ġclimate', 'Ġcommitment', '?']\n",
      " \tquestion_offsets: [0, 5, 8, 12, 19, 24, 28, 36, 46]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 4, 7, 10, 20, 23, 31, 38, 46, 49, 54, 59, 62, 69, 79, 89, 92, 103, 109, 112, 114, 120, 129, 132, 138, 140, 145, 148, 155, 168, 171, 177, 179, 187, 189, 191, 198, 203, 205, 208, 214, 215, 216, 218, 225, 227, 231, 234, 236, 237, 237, 244, 247, 256, 267, 271, 281, 284, 286, 288, 297, 307, 312, 316, 322, 327, 332, 334, 342, 349, 351, 352, 354, 360, 365, 374, 380, 381, 383, 389, 391, 397, 399, 405, 409, 415, 418, 424, 426, 436, 440, 447, 451, 455, 461, 463, 467, 475, 481, 489, 500, 510, 515, 520, 523, 530, 531, 537, 540, 543, 548, 552, 554, 555, 556, 557, 559, 562, 568, 575, 584, 586, 596, 599, 607, 615, 617, 621, 628, 632, 635, 643, 645, 652, 654, 657, 661, 666, 675, 684, 691, 702]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 76, 13, 2147, 2720, 116, 2, 2, 627, 2242, 354, 1288, 15, 2147, 464, 9559, 11, 570, 5026, 7, 1888, 3612, 5035, 9, 11832, 20038, 7, 10, 672, 3833, 7, 3000, 10, 1430, 11, 720, 3971, 7, 874, 132, 4176, 50, 6, 357, 202, 6, 7, 874, 112, 4, 245, 4176, 4, 33760, 3194, 17, 27, 29, 1002, 9, 4881, 11832, 1123, 5035, 30, 1814, 207, 9550, 1786, 31, 5, 1453, 76, 1466, 195, 153, 5657, 1029, 176, 242, 454, 8835, 1171, 7401, 112, 6, 7401, 132, 210, 12, 716, 8, 1667, 9, 7401, 155, 5035, 13, 1007, 8, 935, 1504, 4, 5, 2866, 716, 3247, 3893, 29548, 42, 724, 25, 2866, 12, 805, 11, 16874, 24761, 336, 6, 939, 4, 242, 4, 24, 6616, 720, 2820, 4, 309, 7, 595, 1884, 6, 5, 1002, 64, 28, 4824, 4, 959, 6, 114, 5, 7961, 5364, 3441, 723, 2706, 7267, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [0, 0, 0]\n",
      " \tseq_2_start_t: 12\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/16/2022 15:26:05 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 0-0-0\n",
      "Clear Text: \n",
      " \tpassage_text: the paris agreement on climate change drafted in 2015 aims to reduce worldwide emissions of greenhouse\n",
      "gases to a level intended to limit a rise in global temperatures to below 2 degrees or, better still,\n",
      "to below 1.5 degrees. verbund’s target of reducing greenhouse gas emissions by 90% measured beginning from\n",
      "the basis year 2011 5 million tonnes co2e until 2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions\n",
      "for energy and air travel. the science based targets initiative validated this goal as science-based in october 2016,\n",
      "i.e. it meets global standards. according to current planning, the target can be achieved.\n",
      "however, if the grid operator requires higher generation volumes\n",
      "\n",
      " \tquestion_text: What is the target year for climate commitment?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['the', 'Ġpar', 'is', 'Ġagreement', 'Ġon', 'Ġclimate', 'Ġchange', 'Ġdrafted', 'Ġin', 'Ġ2015', 'Ġaims', 'Ġto', 'Ġreduce', 'Ġworldwide', 'Ġemissions', 'Ġof', 'Ġgreenhouse', 'Ġgases', 'Ġto', 'Ġa', 'Ġlevel', 'Ġintended', 'Ġto', 'Ġlimit', 'Ġa', 'Ġrise', 'Ġin', 'Ġglobal', 'Ġtemperatures', 'Ġto', 'Ġbelow', 'Ġ2', 'Ġdegrees', 'Ġor', ',', 'Ġbetter', 'Ġstill', ',', 'Ġto', 'Ġbelow', 'Ġ1', '.', '5', 'Ġdegrees', '.', 'Ġverb', 'und', 'âĢ', 'Ļ', 's', 'Ġtarget', 'Ġof', 'Ġreducing', 'Ġgreenhouse', 'Ġgas', 'Ġemissions', 'Ġby', 'Ġ90', '%', 'Ġmeasured', 'Ġbeginning', 'Ġfrom', 'Ġthe', 'Ġbasis', 'Ġyear', 'Ġ2011', 'Ġ5', 'Ġmillion', 'Ġtonnes', 'Ġco', '2', 'e', 'Ġuntil', 'Ġ2021', 'Ġincludes', 'Ġscope', 'Ġ1', ',', 'Ġscope', 'Ġ2', 'Ġmarket', '-', 'Ġbased', 'Ġand', 'Ġparts', 'Ġof', 'Ġscope', 'Ġ3', 'Ġemissions', 'Ġfor', 'Ġenergy', 'Ġand', 'Ġair', 'Ġtravel', '.', 'Ġthe', 'Ġscience', 'Ġbased', 'Ġtargets', 'Ġinitiative', 'Ġvalidated', 'Ġthis', 'Ġgoal', 'Ġas', 'Ġscience', '-', 'based', 'Ġin', 'Ġoct', 'ober', 'Ġ2016', ',', 'Ġi', '.', 'e', '.', 'Ġit', 'Ġmeets', 'Ġglobal', 'Ġstandards', '.', 'Ġaccording', 'Ġto', 'Ġcurrent', 'Ġplanning', ',', 'Ġthe', 'Ġtarget', 'Ġcan', 'Ġbe', 'Ġachieved', '.', 'Ġhowever', ',', 'Ġif', 'Ġthe', 'Ġgrid', 'Ġoperator', 'Ġrequires', 'Ġhigher', 'Ġgeneration', 'Ġvolumes']\n",
      " \tpassage_offsets: [0, 4, 7, 10, 20, 23, 31, 38, 46, 49, 54, 59, 62, 69, 79, 89, 92, 103, 109, 112, 114, 120, 129, 132, 138, 140, 145, 148, 155, 168, 171, 177, 179, 187, 189, 191, 198, 203, 205, 208, 214, 215, 216, 218, 225, 227, 231, 234, 236, 237, 237, 244, 247, 256, 267, 271, 281, 284, 286, 288, 297, 307, 312, 316, 322, 327, 332, 334, 342, 349, 351, 352, 354, 360, 365, 374, 380, 381, 383, 389, 391, 397, 399, 405, 409, 415, 418, 424, 426, 436, 440, 447, 451, 455, 461, 463, 467, 475, 481, 489, 500, 510, 515, 520, 523, 530, 531, 537, 540, 543, 548, 552, 554, 555, 556, 557, 559, 562, 568, 575, 584, 586, 596, 599, 607, 615, 617, 621, 628, 632, 635, 643, 645, 652, 654, 657, 661, 666, 675, 684, 691, 702]\n",
      " \tpassage_start_of_word: [1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tquestion_tokens: ['What', 'Ġis', 'Ġthe', 'Ġtarget', 'Ġyear', 'Ġfor', 'Ġclimate', 'Ġcommitment', '?']\n",
      " \tquestion_offsets: [0, 5, 8, 12, 19, 24, 28, 36, 46]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 4, 7, 10, 20, 23, 31, 38, 46, 49, 54, 59, 62, 69, 79, 89, 92, 103, 109, 112, 114, 120, 129, 132, 138, 140, 145, 148, 155, 168, 171, 177, 179, 187, 189, 191, 198, 203, 205, 208, 214, 215, 216, 218, 225, 227, 231, 234, 236, 237, 237, 244, 247, 256, 267, 271, 281, 284, 286, 288, 297, 307, 312, 316, 322, 327, 332, 334, 342, 349, 351, 352, 354, 360, 365, 374, 380, 381, 383, 389, 391, 397, 399, 405, 409, 415, 418, 424, 426, 436, 440, 447, 451, 455, 461, 463, 467, 475, 481, 489, 500, 510, 515, 520, 523, 530, 531, 537, 540, 543, 548, 552, 554, 555, 556, 557, 559, 562, 568, 575, 584, 586, 596, 599, 607, 615, 617, 621, 628, 632, 635, 643, 645, 652, 654, 657, 661, 666, 675, 684, 691, 702]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 1002, 76, 13, 2147, 2720, 116, 2, 2, 627, 2242, 354, 1288, 15, 2147, 464, 9559, 11, 570, 5026, 7, 1888, 3612, 5035, 9, 11832, 20038, 7, 10, 672, 3833, 7, 3000, 10, 1430, 11, 720, 3971, 7, 874, 132, 4176, 50, 6, 357, 202, 6, 7, 874, 112, 4, 245, 4176, 4, 33760, 3194, 17, 27, 29, 1002, 9, 4881, 11832, 1123, 5035, 30, 1814, 207, 9550, 1786, 31, 5, 1453, 76, 1466, 195, 153, 5657, 1029, 176, 242, 454, 8835, 1171, 7401, 112, 6, 7401, 132, 210, 12, 716, 8, 1667, 9, 7401, 155, 5035, 13, 1007, 8, 935, 1504, 4, 5, 2866, 716, 3247, 3893, 29548, 42, 724, 25, 2866, 12, 805, 11, 16874, 24761, 336, 6, 939, 4, 242, 4, 24, 6616, 720, 2820, 4, 309, 7, 595, 1884, 6, 5, 1002, 64, 28, 4824, 4, 959, 6, 114, 5, 7961, 5364, 3441, 723, 2706, 7267, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [0, 0, 0]\n",
      " \tseq_2_start_t: 12\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/16/2022 15:26:06 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
      "07/16/2022 15:26:06 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 5-25-0\n",
      "Clear Text: \n",
      " \tpassage_text: gross scope 1 sf6 emissions metric tons sf6 \n",
      " \tquestion_text: Break down your total gross global Scope 2 emissions by business activity.\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['gross', 'Ġscope', 'Ġ1', 'Ġs', 'f', '6', 'Ġemissions', 'Ġmetric', 'Ġtons', 'Ġs', 'f', '6']\n",
      " \tpassage_offsets: [0, 6, 12, 14, 15, 16, 18, 28, 35, 40, 41, 42]\n",
      " \tpassage_start_of_word: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      " \tquestion_tokens: ['Break', 'Ġdown', 'Ġyour', 'Ġtotal', 'Ġgross', 'Ġglobal', 'ĠScope', 'Ġ2', 'Ġemissions', 'Ġby', 'Ġbusiness', 'Ġactivity', '.']\n",
      " \tquestion_offsets: [0, 6, 11, 16, 22, 28, 35, 41, 43, 53, 56, 65, 73]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 6, 12, 14, 15, 16, 18, 28, 35, 40, 41, 42]\n",
      "Features: \n",
      " \tinput_ids: [0, 39539, 159, 110, 746, 4200, 720, 30108, 132, 5035, 30, 265, 1940, 4, 2, 2, 28961, 7401, 112, 579, 506, 401, 5035, 14823, 7741, 579, 506, 401, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [5, 25, 0]\n",
      " \tseq_2_start_t: 16\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "07/16/2022 15:26:06 - INFO - farm.data_handler.processor -   \n",
      "\n",
      "      .--.        _____                       _      \n",
      "    .'_\\/_'.     / ____|                     | |     \n",
      "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
      "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
      "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
      "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
      "   (/\\||/                             |_|           \n",
      "______\\||/___________________________________________                     \n",
      "\n",
      "ID: 5-1-0\n",
      "Clear Text: \n",
      " \tpassage_text: gross scope 1 sf6 emissions metric tons sf6 \n",
      " \tquestion_text: What is the % change in absolute Scope 3 emissions?\n",
      " \tpassage_id: 0\n",
      " \tanswers: []\n",
      "Tokenized: \n",
      " \tpassage_start_t: 0\n",
      " \tpassage_tokens: ['gross', 'Ġscope', 'Ġ1', 'Ġs', 'f', '6', 'Ġemissions', 'Ġmetric', 'Ġtons', 'Ġs', 'f', '6']\n",
      " \tpassage_offsets: [0, 6, 12, 14, 15, 16, 18, 28, 35, 40, 41, 42]\n",
      " \tpassage_start_of_word: [1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0]\n",
      " \tquestion_tokens: ['What', 'Ġis', 'Ġthe', 'Ġ%', 'Ġchange', 'Ġin', 'Ġabsolute', 'ĠScope', 'Ġ3', 'Ġemissions', '?']\n",
      " \tquestion_offsets: [0, 5, 8, 12, 14, 21, 24, 33, 39, 41, 50]\n",
      " \tquestion_start_of_word: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      " \tanswers: []\n",
      " \tdocument_offsets: [0, 6, 12, 14, 15, 16, 18, 28, 35, 40, 41, 42]\n",
      "Features: \n",
      " \tinput_ids: [0, 2264, 16, 5, 7606, 464, 11, 7833, 30108, 155, 5035, 116, 2, 2, 28961, 7401, 112, 579, 506, 401, 5035, 14823, 7741, 579, 506, 401, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tsegment_ids: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " \tanswer_type_ids: [0]\n",
      " \tpassage_start_t: 0\n",
      " \tstart_of_word: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " \tlabels: [[ 0  0]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]\n",
      " [-1 -1]]\n",
      " \tid: [5, 1, 0]\n",
      " \tseq_2_start_t: 14\n",
      " \tspan_mask: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "_____________________________________________________\n",
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-1:\n",
      "Process ForkPoolWorker-4:\n",
      "Process ForkPoolWorker-3:\n",
      "Process ForkPoolWorker-5:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/queues.py\", line 355, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib64/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = QAInferencer.load(file_config.saved_models_dir, batch_size=40, gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make prediction on a pair of paragraph and question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample context and question\n",
    "context = \"\"\"the paris agreement on climate change drafted in 2015 aims to reduce worldwide emissions of greenhouse\n",
    "gases to a level intended to limit a rise in global temperatures to below 2 degrees or, better still,\n",
    "to below 1.5 degrees. verbund’s target of reducing greenhouse gas emissions by 90% measured beginning from\n",
    "the basis year 2011 5 million tonnes co2e until 2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions\n",
    "for energy and air travel. the science based targets initiative validated this goal as science-based in october 2016,\n",
    "i.e. it meets global standards. according to current planning, the target can be achieved.\n",
    "however, if the grid operator requires higher generation volumes\n",
    "\"\"\"\n",
    "question = \"What is the target year for climate commitment?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 19.71 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'answers': [{'answer': 'no_answer',\n",
      "                               'context': '',\n",
      "                               'document_id': '0-0',\n",
      "                               'offset_answer_end': 0,\n",
      "                               'offset_answer_start': 0,\n",
      "                               'offset_context_end': 0,\n",
      "                               'offset_context_start': 0,\n",
      "                               'probability': None,\n",
      "                               'score': 6.441586971282959},\n",
      "                              {'answer': '2021 includes scope 1, scope 2 '\n",
      "                                         'market- based and parts of scope 3 '\n",
      "                                         'emissions\\n'\n",
      "                                         'for energy and air travel. the '\n",
      "                                         'science based targets initiative '\n",
      "                                         'validated this goal as science-based '\n",
      "                                         'in october 2016,\\n'\n",
      "                                         'i.',\n",
      "                               'context': '2021 includes scope 1, scope 2 '\n",
      "                                          'market- based and parts of scope 3 '\n",
      "                                          'emissions\\n'\n",
      "                                          'for energy and air travel. the '\n",
      "                                          'science based targets initiative '\n",
      "                                          'validated this goal as '\n",
      "                                          'science-based in october 2016,\\n'\n",
      "                                          'i.',\n",
      "                               'document_id': '0-0',\n",
      "                               'offset_answer_end': 556,\n",
      "                               'offset_answer_start': 360,\n",
      "                               'offset_context_end': 556,\n",
      "                               'offset_context_start': 360,\n",
      "                               'probability': None,\n",
      "                               'score': -13.357474327087402}],\n",
      "                  'ground_truth': [],\n",
      "                  'id': '0-0',\n",
      "                  'no_ans_gap': -19.79906129837036,\n",
      "                  'question': 'What is the target year for climate '\n",
      "                              'commitment?'}],\n",
      " 'task': 'qa'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model response\n",
    "QA_input = [\n",
    "    {\n",
    "        \"qas\": [question],\n",
    "        \"context\":  context\n",
    "    }\n",
    "]\n",
    "\n",
    "result = model.inference_from_dicts(dicts=QA_input)[0]\n",
    "pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the prediction result show? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 6.441586971282959,\n",
       " 'probability': None,\n",
       " 'answer': 'no_answer',\n",
       " 'offset_answer_start': 0,\n",
       " 'offset_answer_end': 0,\n",
       " 'context': '',\n",
       " 'offset_context_start': 0,\n",
       " 'offset_context_end': 0,\n",
       " 'document_id': '0-0'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the best answer. Generally it can be span-based or it can be no-answer, which ever is higher\n",
    "# Here the top answer is the span '2021'\n",
    "result['predictions'][0]['answers'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': -13.357474327087402,\n",
       " 'probability': None,\n",
       " 'answer': '2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions\\nfor energy and air travel. the science based targets initiative validated this goal as science-based in october 2016,\\ni.',\n",
       " 'offset_answer_start': 360,\n",
       " 'offset_answer_end': 556,\n",
       " 'context': '2021 includes scope 1, scope 2 market- based and parts of scope 3 emissions\\nfor energy and air travel. the science based targets initiative validated this goal as science-based in october 2016,\\ni.',\n",
       " 'offset_context_start': 360,\n",
       " 'offset_context_end': 556,\n",
       " 'document_id': '0-0'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-answerable score: The model is pretty confident that the answer to the question can be in the context.\n",
    "result['predictions'][0]['answers'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Next, we will make the predictions on the squad-formatted validation file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.41 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.00 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.80 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.67 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.51 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.44 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.73 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.72 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.82 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 5/5 [00:02<00:00,  2.15 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  4.89 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  3.60 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  1.97 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 4/4 [00:01<00:00,  2.24 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.99 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.43 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 3/3 [00:01<00:00,  2.42 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.94 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.23 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:01<00:00,  1.84 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.09 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.20 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 4/4 [00:02<00:00,  1.92 Batches/s]\n",
      "Inferencing Samples: 100%|██████████| 2/2 [00:00<00:00,  3.19 Batches/s]\n",
      "07/16/2022 15:26:38 - INFO - farm.data_handler.utils -   Written Squad predictions to: /opt/app-root/src/aicoe-osc-demo-MichaelTiemannOSC/reports/qa_predictions.json\n"
     ]
    }
   ],
   "source": [
    "# run inference on validation dataset\n",
    "results = model.inference_from_file(\n",
    "    file=file_config.dev_filename,\n",
    "    return_json=False,\n",
    ")\n",
    "result_squad = [x.to_squad_eval() for x in results]\n",
    "\n",
    "write_squad_predictions(\n",
    "    predictions=result_squad,\n",
    "    predictions_filename=file_config.dev_filename,\n",
    "    out_filename=file_config.dev_predictions_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is written in the `out_filename`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate the model usong the squad evaluation tool provided by farm\n",
    "# settings for squad evaluation\n",
    "eval_params = {\n",
    "    \"data_file\": file_config.dev_filename,\n",
    "    \"pred_file\": file_config.dev_predictions_filename,\n",
    "    \"out_file\": file_config.model_performance_metrics_filename,\n",
    "    \"na_prob_thresh\": 1,\n",
    "    \"na_prob_file\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exact</th>\n",
       "      <th>f1</th>\n",
       "      <th>total</th>\n",
       "      <th>HasAns_exact</th>\n",
       "      <th>HasAns_f1</th>\n",
       "      <th>HasAns_total</th>\n",
       "      <th>NoAns_exact</th>\n",
       "      <th>NoAns_f1</th>\n",
       "      <th>NoAns_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99.013921</td>\n",
       "      <td>99.013921</td>\n",
       "      <td>1724</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>99.941452</td>\n",
       "      <td>99.941452</td>\n",
       "      <td>1708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       exact         f1  total  HasAns_exact  HasAns_f1  HasAns_total  \\\n",
       "0  99.013921  99.013921   1724           0.0        0.0            16   \n",
       "\n",
       "   NoAns_exact   NoAns_f1  NoAns_total  \n",
       "0    99.941452  99.941452         1708  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(eval_params['data_file']) as f:\n",
    "    dataset_json = json.load(f)\n",
    "    dataset = dataset_json['data']\n",
    "\n",
    "with open(eval_params['pred_file']) as f:\n",
    "    preds = json.load(f)\n",
    "\n",
    "# NOTE: in predictions, the keys are strings but need to be converted to ints\n",
    "# if we want to use squad evaluation file provided by farm\n",
    "preds = {int(k): v for k, v in preds.items()}\n",
    "\n",
    "if eval_params['na_prob_file']:\n",
    "    with open(eval_params['na_prob_file']) as f:\n",
    "        na_probs = json.load(f)\n",
    "else:\n",
    "    na_probs = {k: 0.0 for k in preds}\n",
    "\n",
    "# maps qid to True/False\n",
    "qid_to_has_ans = squad_evaluation.make_qid_to_has_ans(dataset)\n",
    "has_ans_qids = [k for k, v in qid_to_has_ans.items() if v]\n",
    "no_ans_qids = [k for k, v in qid_to_has_ans.items() if not v]\n",
    "\n",
    "# get raw scores\n",
    "exact_raw, f1_raw = squad_evaluation.get_raw_scores_extended(dataset, preds)\n",
    "\n",
    "# apply thresholds\n",
    "exact_thresh = squad_evaluation.apply_no_ans_threshold(\n",
    "    exact_raw,\n",
    "    na_probs,\n",
    "    qid_to_has_ans,\n",
    "    eval_params['na_prob_thresh'],\n",
    ")\n",
    "f1_thresh = squad_evaluation.apply_no_ans_threshold(\n",
    "    f1_raw,\n",
    "    na_probs,\n",
    "    qid_to_has_ans,\n",
    "    eval_params['na_prob_thresh'],\n",
    ")\n",
    "\n",
    "# create results dict\n",
    "results_squad = squad_evaluation.make_eval_dict(exact_thresh, f1_thresh)\n",
    "if has_ans_qids:\n",
    "    has_ans_eval = squad_evaluation.make_eval_dict(exact_thresh, f1_thresh, qid_list=has_ans_qids)\n",
    "    squad_evaluation.merge_eval(results_squad, has_ans_eval, 'HasAns')\n",
    "if no_ans_qids:\n",
    "    no_ans_eval = squad_evaluation.make_eval_dict(exact_thresh, f1_thresh, qid_list=no_ans_qids)\n",
    "    squad_evaluation.merge_eval(results_squad, no_ans_eval, 'NoAns')\n",
    "\n",
    "# covert to df\n",
    "scores_df = pd.DataFrame(results_squad, index=[0])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'MJ9R4Q0G6100K241',\n",
       "  'HostId': 'tTI7/d234lKo9vjg8QIRb0vgZWDTJ0mgYR9cediTil0UUfwk+PUqA1VCklAKm8qa255g/6sBEk8=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'tTI7/d234lKo9vjg8QIRb0vgZWDTJ0mgYR9cediTil0UUfwk+PUqA1VCklAKm8qa255g/6sBEk8=',\n",
       "   'x-amz-request-id': 'MJ9R4Q0G6100K241',\n",
       "   'date': 'Sat, 16 Jul 2022 15:26:39 GMT',\n",
       "   'etag': '\"e022952b4de8c4ad0770dcf1f8f94ca1\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"e022952b4de8c4ad0770dcf1f8f94ca1\"'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save locally and upload to s3\n",
    "scores_df.to_csv(file_config.model_performance_metrics_filename)\n",
    "\n",
    "# upload performance files to s3\n",
    "s3c.upload_df_to_s3(\n",
    "    scores_df,\n",
    "    s3_prefix=f\"{config.BASE_SAVED_MODELS_S3_PREFIX}\",\n",
    "    s3_key=\"kpi_scores.csv\",\n",
    "    filetype=S3FileType.CSV,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save Model to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = BytesIO()\n",
    "with zipfile.ZipFile(buffer, 'a') as z:\n",
    "    for dirname, _, files in os.walk(f\"{file_config.saved_models_dir}\"):\n",
    "        for f in files:\n",
    "            f_path = os.path.join(dirname, f)\n",
    "            with open (f_path, 'rb') as file_content:\n",
    "                z.writestr(f\"KPI_EXTRACTION/{f}\", file_content.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'P9KH1ESDC34A7ZVJ',\n",
       "  'HostId': '2aHtkbYvKG2XP8G0Y+NtO7ySHRKMx6bBVzZ4wqEh/dbsZCOpgTQLUVDMj1q15LMjlJ9LkxrP/PU=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': '2aHtkbYvKG2XP8G0Y+NtO7ySHRKMx6bBVzZ4wqEh/dbsZCOpgTQLUVDMj1q15LMjlJ9LkxrP/PU=',\n",
       "   'x-amz-request-id': 'P9KH1ESDC34A7ZVJ',\n",
       "   'date': 'Sat, 16 Jul 2022 15:26:45 GMT',\n",
       "   'etag': '\"59a8d7a845635a5328fe6780dd14c580\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"59a8d7a845635a5328fe6780dd14c580\"'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.seek(0)\n",
    "# upload model to s3\n",
    "s3c._upload_bytes(\n",
    "    buffer_bytes=buffer,\n",
    "    prefix=config.BASE_SAVED_MODELS_S3_PREFIX,\n",
    "    key=\"KPI_EXTRACTION.zip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we developed a model that can be used for answering a KPI question, given a relevant paragraph (context). With this model in place, the training pipeline is now complete. That is, we have a pipeline that takes a set of raw PDFs, runs extraction, curates the data for relevance training, trains a relevance model, curates the relevance results for question-answering training, and finally trains a question-answering model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
